{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51977a6f",
   "metadata": {},
   "source": [
    "# TEMPO Data Inspection Notebook\n",
    "## Understanding Current Data Structure\n",
    "\n",
    "This notebook inspects the current standardized data to understand:\n",
    "1. Column structure across datasets\n",
    "2. Current emotion label format (need to map 27 → 13)\n",
    "3. Event types and informativeness values\n",
    "4. Data quality and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfee512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b805058",
   "metadata": {},
   "source": [
    "## 1. Check Available Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ee51b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 CSV files:\n",
      "\n",
      "  coachella_standardized.csv                   0.56 MB\n",
      "  crisis_combined.csv                         12.91 MB\n",
      "  crisislex_standardized.csv                   4.59 MB\n",
      "  fifa_worldcup_standardized.csv              12.00 MB\n",
      "  game_of_thrones_standardized.csv           142.61 MB\n",
      "  humaid_standardized.csv                      8.32 MB\n",
      "  music_concerts_standardized.csv              0.45 MB\n",
      "  non_crisis_combined.csv                    265.68 MB\n",
      "  tokyo_olympics_standardized.csv             29.49 MB\n",
      "  us_election_standardized.csv                23.67 MB\n",
      "  worldcup_2018_standardized.csv              56.89 MB\n"
     ]
    }
   ],
   "source": [
    "# List all CSV files in standardized_data\n",
    "data_dir = Path('standardized_data')\n",
    "csv_files = list(data_dir.glob('*.csv'))\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files:\\n\")\n",
    "for file in sorted(csv_files):\n",
    "    size_mb = file.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  {file.name:<40} {size_mb:>8.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39168f20",
   "metadata": {},
   "source": [
    "## 2. Inspect Crisis Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa4e1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CRISIS COMBINED DATASET\n",
      "================================================================================\n",
      "\n",
      "Total rows: 66,748\n",
      "\n",
      "Columns (7): ['text', 'created_at', 'event_name', 'event_type', 'crisis_label', 'source_dataset', 'informativeness']\n",
      "\n",
      "Data types:\n",
      "text               object\n",
      "created_at         object\n",
      "event_name         object\n",
      "event_type         object\n",
      "crisis_label        int64\n",
      "source_dataset     object\n",
      "informativeness    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load crisis data\n",
    "crisis_df = pd.read_csv('standardized_data/crisis_combined.csv')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CRISIS COMBINED DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal rows: {len(crisis_df):,}\")\n",
    "print(f\"\\nColumns ({len(crisis_df.columns)}): {crisis_df.columns.tolist()}\")\n",
    "print(f\"\\nData types:\\n{crisis_df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99372115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 3 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_type</th>\n",
       "      <th>crisis_label</th>\n",
       "      <th>source_dataset</th>\n",
       "      <th>informativeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@GreenABEnergy How can @AirworksCanada assist in the cleanup? #AlbertaStrong</td>\n",
       "      <td>2016-05-19 18:16:11.727000+00:00</td>\n",
       "      <td>canada_wildfires_2016_dev</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>1</td>\n",
       "      <td>humaid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @katvondawn: Thoughts &amp;amp; prayers going to all those being affected by the wildfire in Cana...</td>\n",
       "      <td>2016-05-09 03:58:37.448000+00:00</td>\n",
       "      <td>canada_wildfires_2016_dev</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>1</td>\n",
       "      <td>humaid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glacier Farm Media pledges $50K in support for Fort McMurray wildfire disaster relief.</td>\n",
       "      <td>2016-05-12 12:41:05.044000+00:00</td>\n",
       "      <td>canada_wildfires_2016_dev</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>1</td>\n",
       "      <td>humaid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0                        .@GreenABEnergy How can @AirworksCanada assist in the cleanup? #AlbertaStrong   \n",
       "1  RT @katvondawn: Thoughts &amp; prayers going to all those being affected by the wildfire in Cana...   \n",
       "2               Glacier Farm Media pledges $50K in support for Fort McMurray wildfire disaster relief.   \n",
       "\n",
       "                         created_at                 event_name event_type  \\\n",
       "0  2016-05-19 18:16:11.727000+00:00  canada_wildfires_2016_dev   wildfire   \n",
       "1  2016-05-09 03:58:37.448000+00:00  canada_wildfires_2016_dev   wildfire   \n",
       "2  2016-05-12 12:41:05.044000+00:00  canada_wildfires_2016_dev   wildfire   \n",
       "\n",
       "   crisis_label source_dataset informativeness  \n",
       "0             1         humaid             NaN  \n",
       "1             1         humaid             NaN  \n",
       "2             1         humaid             NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first few rows\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "crisis_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0806179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INFORMATIVENESS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Informativeness value counts:\n",
      "informativeness\n",
      "related_informative        14379\n",
      "related_not_informative     6257\n",
      "not_related                 2296\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Informativeness data type: object\n",
      "Missing values: 43816\n"
     ]
    }
   ],
   "source": [
    "# Check informativeness values\n",
    "print(\"=\" * 80)\n",
    "print(\"INFORMATIVENESS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'informativeness' in crisis_df.columns:\n",
    "    print(f\"\\nInformativeness value counts:\")\n",
    "    print(crisis_df['informativeness'].value_counts())\n",
    "    print(f\"\\nInformativeness data type: {crisis_df['informativeness'].dtype}\")\n",
    "    print(f\"Missing values: {crisis_df['informativeness'].isna().sum()}\")\n",
    "else:\n",
    "    print(\"\\nNo 'informativeness' column found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f6ac805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVENT TYPE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Unique event types (7):\n",
      "event_type\n",
      "hurricane     33422\n",
      "earthquake    11429\n",
      "flood          7498\n",
      "wildfire       7151\n",
      "accident       4248\n",
      "bombing        2000\n",
      "haze           1000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check event types\n",
    "print(\"=\" * 80)\n",
    "print(\"EVENT TYPE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'event_type' in crisis_df.columns:\n",
    "    print(f\"\\nUnique event types ({crisis_df['event_type'].nunique()}):\")\n",
    "    print(crisis_df['event_type'].value_counts())\n",
    "else:\n",
    "    print(\"\\nNo 'event_type' column found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08cf77c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EMOTION COLUMNS IN CRISIS DATA\n",
      "================================================================================\n",
      "\n",
      "Found 0 emotion columns: []\n"
     ]
    }
   ],
   "source": [
    "# Check for emotion columns\n",
    "print(\"=\" * 80)\n",
    "print(\"EMOTION COLUMNS IN CRISIS DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "emotion_cols = [col for col in crisis_df.columns if 'emotion' in col.lower()]\n",
    "print(f\"\\nFound {len(emotion_cols)} emotion columns: {emotion_cols}\")\n",
    "\n",
    "if emotion_cols:\n",
    "    print(\"\\nSample emotion values:\")\n",
    "    print(crisis_df[emotion_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470877f9",
   "metadata": {},
   "source": [
    "## 3. Inspect Non-Crisis Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8a8fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NON-CRISIS COMBINED DATASET\n",
      "================================================================================\n",
      "\n",
      "Total rows: 1,533,696\n",
      "\n",
      "Columns (6): ['text', 'created_at', 'event_name', 'event_type', 'crisis_label', 'source_dataset']\n",
      "\n",
      "Data types:\n",
      "text              object\n",
      "created_at        object\n",
      "event_name        object\n",
      "event_type        object\n",
      "crisis_label       int64\n",
      "source_dataset    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load non-crisis data\n",
    "non_crisis_df = pd.read_csv('standardized_data/non_crisis_combined.csv')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NON-CRISIS COMBINED DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal rows: {len(non_crisis_df):,}\")\n",
    "print(f\"\\nColumns ({len(non_crisis_df.columns)}): {non_crisis_df.columns.tolist()}\")\n",
    "print(f\"\\nData types:\\n{non_crisis_df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecb4e662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 3 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_type</th>\n",
       "      <th>crisis_label</th>\n",
       "      <th>source_dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Coachella2015 tickets selling out in less than 40 minutes _Ù_¦_Ù___Ù___Ù÷_ÙÎµ_ÙÎµ_Ù___Ù_¦ http...</td>\n",
       "      <td>2015-01-07 15:02:00</td>\n",
       "      <td>coachella_2015</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0</td>\n",
       "      <td>coachella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @sudsybuddy: WAIT THIS IS ABSOLUTE FIRE _ÙÓ´_ÙÓ´_ÙÓ´ #Coachella2015 http://t.co/Ov2eCJtAvR</td>\n",
       "      <td>2015-01-07 15:02:00</td>\n",
       "      <td>coachella_2015</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0</td>\n",
       "      <td>coachella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Coachella2015 #VIP passes secured! See you there bitchesssss</td>\n",
       "      <td>2015-01-07 15:01:00</td>\n",
       "      <td>coachella_2015</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0</td>\n",
       "      <td>coachella</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  #Coachella2015 tickets selling out in less than 40 minutes _Ù_¦_Ù___Ù___Ù÷_ÙÎµ_ÙÎµ_Ù___Ù_¦ http...   \n",
       "1        RT @sudsybuddy: WAIT THIS IS ABSOLUTE FIRE _ÙÓ´_ÙÓ´_ÙÓ´ #Coachella2015 http://t.co/Ov2eCJtAvR   \n",
       "2                                        #Coachella2015 #VIP passes secured! See you there bitchesssss   \n",
       "\n",
       "            created_at      event_name     event_type  crisis_label  \\\n",
       "0  2015-01-07 15:02:00  coachella_2015  entertainment             0   \n",
       "1  2015-01-07 15:02:00  coachella_2015  entertainment             0   \n",
       "2  2015-01-07 15:01:00  coachella_2015  entertainment             0   \n",
       "\n",
       "  source_dataset  \n",
       "0      coachella  \n",
       "1      coachella  \n",
       "2      coachella  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first few rows\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "non_crisis_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d75b686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NON-CRISIS EVENT TYPES\n",
      "================================================================================\n",
      "\n",
      "Event type distribution:\n",
      "event_type\n",
      "entertainment    766290\n",
      "sports           667458\n",
      "politics          99948\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Event name distribution:\n",
      "event_name\n",
      "got_season8_2019       760614\n",
      "fifa_worldcup_2018     458533\n",
      "tokyo_olympics_2020    159432\n",
      "us_election_2020        99948\n",
      "fifa_worldcup_2022      49493\n",
      "coachella_2015           3846\n",
      "music_concerts_2021      1830\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check event types in non-crisis\n",
    "print(\"=\" * 80)\n",
    "print(\"NON-CRISIS EVENT TYPES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'event_type' in non_crisis_df.columns:\n",
    "    print(f\"\\nEvent type distribution:\")\n",
    "    print(non_crisis_df['event_type'].value_counts())\n",
    "\n",
    "if 'event_name' in non_crisis_df.columns:\n",
    "    print(f\"\\nEvent name distribution:\")\n",
    "    print(non_crisis_df['event_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df048efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NON-CRISIS INFORMATIVENESS\n",
      "================================================================================\n",
      "\n",
      "No 'informativeness' column in non-crisis data\n"
     ]
    }
   ],
   "source": [
    "# Check informativeness in non-crisis\n",
    "print(\"=\" * 80)\n",
    "print(\"NON-CRISIS INFORMATIVENESS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'informativeness' in non_crisis_df.columns:\n",
    "    print(f\"\\nInformativeness values:\")\n",
    "    print(non_crisis_df['informativeness'].value_counts())\n",
    "    print(f\"\\nMissing: {non_crisis_df['informativeness'].isna().sum()}\")\n",
    "else:\n",
    "    print(\"\\nNo 'informativeness' column in non-crisis data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5ef9e",
   "metadata": {},
   "source": [
    "## 4. Check for GoEmotions Data (27 Emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f079032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GoEmotions data found!\n",
      "\n",
      "================================================================================\n",
      "GOEMOTIONS DATASET (27 EMOTIONS)\n",
      "================================================================================\n",
      "\n",
      "Columns: ['text', 'labels', 'id', 'Unnamed: 3', '[27] = neutral [0] = admiration [1] = amusement [2] = anger [3] = annoyance [4] = approval [5] = caring [6] = confusion [7] = curiosity [8] = desire [9] = disappointment [10] = disapproval [11] = disgust [12] = embarrassment [13] = excitement [14] = fear [15] = gratitude [16] = grief [17] = joy [18] = love [19] = nervousness [20] = optimism [21] = pride [22] = realization [23] = relief [24] = remorse [25] = sadness [26] = surprise [27] = neutral']\n",
      "\n",
      "First 3 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>[27] = neutral [0] = admiration [1] = amusement [2] = anger [3] = annoyance [4] = approval [5] = caring [6] = confusion [7] = curiosity [8] = desire [9] = disappointment [10] = disapproval [11] = disgust [12] = embarrassment [13] = excitement [14] = fear [15] = gratitude [16] = grief [17] = joy [18] = love [19] = nervousness [20] = optimism [21] = pride [22] = realization [23] = relief [24] = remorse [25] = sadness [26] = surprise [27] = neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to cook myself.</td>\n",
       "      <td>[27]</td>\n",
       "      <td>eebbqej</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will think hes having a laugh screwing with people instead ...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>ed00q6i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>eezlygj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0                                          My favourite food is anything I didn't have to cook myself.   \n",
       "1  Now if he does off himself, everyone will think hes having a laugh screwing with people instead ...   \n",
       "2                                                                       WHY THE FUCK IS BAYLESS ISOING   \n",
       "\n",
       "  labels       id  Unnamed: 3  \\\n",
       "0   [27]  eebbqej         NaN   \n",
       "1   [27]  ed00q6i         NaN   \n",
       "2    [2]  eezlygj         NaN   \n",
       "\n",
       "   [27] = neutral [0] = admiration [1] = amusement [2] = anger [3] = annoyance [4] = approval [5] = caring [6] = confusion [7] = curiosity [8] = desire [9] = disappointment [10] = disapproval [11] = disgust [12] = embarrassment [13] = excitement [14] = fear [15] = gratitude [16] = grief [17] = joy [18] = love [19] = nervousness [20] = optimism [21] = pride [22] = realization [23] = relief [24] = remorse [25] = sadness [26] = surprise [27] = neutral  \n",
       "0                                                                                                  NaN                                                                                                                                                                                                                                                                                                                                                                \n",
       "1                                                                                                  NaN                                                                                                                                                                                                                                                                                                                                                                \n",
       "2                                                                                                  NaN                                                                                                                                                                                                                                                                                                                                                                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Emotion-related columns: []\n"
     ]
    }
   ],
   "source": [
    "# Check if goemotion_data exists\n",
    "goemotion_path = Path('goemotion_data/goemotions.csv')\n",
    "\n",
    "if goemotion_path.exists():\n",
    "    print(\"✓ GoEmotions data found!\\n\")\n",
    "    \n",
    "    # Load a sample\n",
    "    goemotions_df = pd.read_csv(goemotion_path, nrows=1000)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"GOEMOTIONS DATASET (27 EMOTIONS)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nColumns: {goemotions_df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst 3 rows:\")\n",
    "    display(goemotions_df.head(3))\n",
    "    \n",
    "    # Check emotion columns\n",
    "    emotion_cols = [col for col in goemotions_df.columns if 'emotion' in col.lower()]\n",
    "    print(f\"\\nEmotion-related columns: {emotion_cols}\")\n",
    "    \n",
    "else:\n",
    "    print(\"✗ GoEmotions data NOT found at goemotion_data/goemotions.csv\")\n",
    "    print(\"  You need to download this from Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1038d9",
   "metadata": {},
   "source": [
    "## 5. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25519cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✓ Crisis data: 66,748 rows\n",
      "✓ Non-crisis data: 1,533,696 rows\n",
      "\n",
      "================================================================================\n",
      "NEXT STEPS\n",
      "================================================================================\n",
      "\n",
      "1. Download missing data folders from Google Drive:\n",
      "   - goemotion_data/ (for 27 emotion labels)\n",
      "   - master_training_data/ (if already processed)\n",
      "   - baseline_data/ (optional - for noise tweets)\n",
      "\n",
      "2. Map 27 GoEmotions → 13 emotions (need to define which 13!)\n",
      "\n",
      "3. Understand informativeness values:\n",
      "   - What do the current values mean?\n",
      "   - Binary (0/1)? Categorical? Scale?\n",
      "\n",
      "4. Decide event_type labels for non-crisis data\n",
      "\n",
      "5. Refactor code to industry standards\n",
      "\n",
      "6. Convert Python scripts to notebooks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n✓ Crisis data: {len(crisis_df):,} rows\")\n",
    "print(f\"✓ Non-crisis data: {len(non_crisis_df):,} rows\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. Download missing data folders from Google Drive:\n",
    "   - goemotion_data/ (for 27 emotion labels)\n",
    "   - master_training_data/ (if already processed)\n",
    "   - baseline_data/ (optional - for noise tweets)\n",
    "\n",
    "2. Map 27 GoEmotions → 13 emotions (need to define which 13!)\n",
    "\n",
    "3. Understand informativeness values:\n",
    "   - What do the current values mean?\n",
    "   - Binary (0/1)? Categorical? Scale?\n",
    "\n",
    "4. Decide event_type labels for non-crisis data\n",
    "\n",
    "5. Refactor code to industry standards\n",
    "\n",
    "6. Convert Python scripts to notebooks\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
