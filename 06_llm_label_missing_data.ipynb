{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: LLM-Based Data Labeling\n",
    "## Fill Missing Values Using Gemini 2.0 Flash API\n",
    "\n",
    "This notebook uses Google's Gemini 2.0 Flash to fill missing values in the master training dataset (v5).\n",
    "\n",
    "### Prerequisites:\n",
    "- Run notebook 05 first to create `master_training_data_v5.csv` (60K stratified rows)\n",
    "\n",
    "### What we're filling:\n",
    "\n",
    "| Source | Missing Columns | Rows |\n",
    "|--------|-----------------|------|\n",
    "| Crisis tweets | emotion_label, emotion_name | ~25K |\n",
    "| Non-crisis tweets | emotion_label, emotion_name | ~18K |\n",
    "| GoEmotions | crisis_label, event_type, event_name, informativeness | ~17K |\n",
    "\n",
    "### Strategy (per mentor's advice):\n",
    "- Process **one row at a time** for better accuracy\n",
    "- Each tweet gets its own API call\n",
    "- Save progress periodically to handle interruptions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "# !pip install google-generativeai python-dotenv tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"âœ… Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from .env file\n",
    "GEMINI_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if not GEMINI_API_KEY or GEMINI_API_KEY == 'your_api_key_here':\n",
    "    print(\"âš ï¸  Please set your Gemini API key in the .env file!\")\n",
    "    print(\"   1. Open .env file in your project root\")\n",
    "    print(\"   2. Replace 'your_api_key_here' with your actual API key\")\n",
    "    print(\"   3. Get a key at: https://makersuite.google.com/app/apikey\")\n",
    "else:\n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    print(\"âœ… Gemini API configured from .env file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "# Options: \n",
    "#   - \"gemini-2.0-flash\" (recommended - good balance of speed/quality)\n",
    "#   - \"gemini-2.0-flash-lite\" (cheaper but lower accuracy)\n",
    "#   - \"gemini-1.5-flash\" (previous gen, also good)\n",
    "MODEL_NAME = \"gemini-2.0-flash\"\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=MODEL_NAME,\n",
    "    generation_config={\n",
    "        \"temperature\": 0.1,  # Low temperature for consistent classification\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_output_tokens\": 100,  # We only need short responses\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"âœ… Model initialized: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Master Dataset (v5 - 60K stratified rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stratified master training dataset from notebook 05\n",
    "MASTER_PATH = 'master_training_data/master_training_data_v5.csv'\n",
    "\n",
    "df = pd.read_csv(MASTER_PATH)\n",
    "print(f\"âœ… Loaded {len(df):,} rows from {MASTER_PATH}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nNull counts:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nSource distribution:\")\n",
    "print(df['source_dataset'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with null text (can't classify empty text)\n",
    "null_text_count = df['text'].isna().sum()\n",
    "if null_text_count > 0:\n",
    "    print(f\"Removing {null_text_count} rows with null text...\")\n",
    "    df = df[df['text'].notna()].reset_index(drop=True)\n",
    "    print(f\"Remaining rows: {len(df):,}\")\n",
    "else:\n",
    "    print(\"âœ… No null text rows found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Classification Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion mapping (label -> name)\n",
    "EMOTION_MAP = {\n",
    "    1: \"admiration\",\n",
    "    2: \"anger\",\n",
    "    3: \"annoyance\",\n",
    "    4: \"caring\",\n",
    "    5: \"confusion\",\n",
    "    6: \"curiosity\",\n",
    "    7: \"desire\",\n",
    "    8: \"disappointment\",\n",
    "    9: \"fear\",\n",
    "    10: \"gratitude\",\n",
    "    11: \"joy\",\n",
    "    12: \"amusement\",\n",
    "    13: \"neutral\"\n",
    "}\n",
    "\n",
    "# Reverse mapping (name -> label)\n",
    "EMOTION_NAME_TO_LABEL = {v: k for k, v in EMOTION_MAP.items()}\n",
    "\n",
    "# Informativeness labels (from CrisisLex)\n",
    "INFORMATIVENESS_LABELS = [\n",
    "    \"related_informative\",\n",
    "    \"related_not_informative\",\n",
    "    \"not_related\"\n",
    "]\n",
    "\n",
    "print(\"13 Emotion categories:\")\n",
    "for label, name in EMOTION_MAP.items():\n",
    "    print(f\"  {label}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for classifying EMOTION (for Crisis/Non-crisis tweets)\n",
    "EMOTION_PROMPT_TEMPLATE = \"\"\"Classify the emotion in this tweet into exactly ONE of these 13 categories:\n",
    "1. admiration - respect, approval for someone/something\n",
    "2. anger - strong displeasure, hostility\n",
    "3. annoyance - mild irritation, frustration\n",
    "4. caring - concern, empathy for others\n",
    "5. confusion - uncertainty, bewilderment\n",
    "6. curiosity - desire to learn or know\n",
    "7. desire - wanting something\n",
    "8. disappointment - sadness from unmet expectations\n",
    "9. fear - anxiety, worry, being scared\n",
    "10. gratitude - thankfulness, appreciation\n",
    "11. joy - happiness, excitement, celebration\n",
    "12. amusement - finding something funny/entertaining\n",
    "13. neutral - no strong emotion, factual statement\n",
    "\n",
    "Tweet: \"{text}\"\n",
    "\n",
    "Respond with ONLY the emotion name (one word, lowercase). Nothing else.\"\"\"\n",
    "\n",
    "\n",
    "# Prompt for classifying GoEmotions data (crisis_label, event_type, informativeness)\n",
    "GOEMOTIONS_PROMPT_TEMPLATE = \"\"\"Analyze this Reddit comment and determine:\n",
    "1. Is it related to a crisis/disaster/emergency? (yes/no)\n",
    "2. If crisis-related, what type? (hurricane, earthquake, flood, wildfire, terrorism, shooting, pandemic, other_crisis)\n",
    "   If NOT crisis-related, use: general_discussion\n",
    "3. Informativeness: \n",
    "   - \"related_informative\" = discusses crisis with useful info\n",
    "   - \"related_not_informative\" = mentions crisis but no useful info\n",
    "   - \"not_related\" = not about any crisis\n",
    "\n",
    "Comment: \"{text}\"\n",
    "\n",
    "Respond in this EXACT format (3 lines):\n",
    "crisis: yes or no\n",
    "event_type: <type>\n",
    "informativeness: <label>\"\"\"\n",
    "\n",
    "print(\"âœ… Prompt templates defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_emotion(text, max_retries=3):\n",
    "    \"\"\"Classify the emotion of a tweet using Gemini.\"\"\"\n",
    "    prompt = EMOTION_PROMPT_TEMPLATE.format(text=text[:500])\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            emotion_name = response.text.strip().lower()\n",
    "            \n",
    "            if emotion_name in EMOTION_NAME_TO_LABEL:\n",
    "                return EMOTION_NAME_TO_LABEL[emotion_name], emotion_name\n",
    "            else:\n",
    "                for name in EMOTION_NAME_TO_LABEL:\n",
    "                    if name in emotion_name:\n",
    "                        return EMOTION_NAME_TO_LABEL[name], name\n",
    "                return 13, \"neutral\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "            else:\n",
    "                print(f\"Error: {str(e)[:50]}\")\n",
    "                return None, None\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def classify_goemotions_row(text, max_retries=3):\n",
    "    \"\"\"Classify a GoEmotions comment for crisis-related fields.\"\"\"\n",
    "    prompt = GOEMOTIONS_PROMPT_TEMPLATE.format(text=text[:500])\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            lines = response.text.strip().lower().split('\\n')\n",
    "            \n",
    "            crisis_label = 0\n",
    "            event_type = \"general_discussion\"\n",
    "            informativeness = \"not_related\"\n",
    "            \n",
    "            for line in lines:\n",
    "                if 'crisis:' in line:\n",
    "                    crisis_label = 1 if 'yes' in line else 0\n",
    "                elif 'event_type:' in line:\n",
    "                    event_type = line.split(':')[1].strip()\n",
    "                elif 'informativeness:' in line:\n",
    "                    info = line.split(':')[1].strip()\n",
    "                    if 'not_related' in info or 'not related' in info:\n",
    "                        informativeness = 'not_related'\n",
    "                    elif 'not_informative' in info:\n",
    "                        informativeness = 'related_not_informative'\n",
    "                    elif 'informative' in info:\n",
    "                        informativeness = 'related_informative'\n",
    "            \n",
    "            event_name = event_type\n",
    "            return crisis_label, event_type, event_name, informativeness\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "            else:\n",
    "                print(f\"Error: {str(e)[:50]}\")\n",
    "                return None, None, None, None\n",
    "    return None, None, None, None\n",
    "\n",
    "print(\"âœ… Classification functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Classification (Verify API works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test emotion classification\n",
    "print(\"Testing emotion classification...\")\n",
    "test1 = \"Pray for the victims of the hurricane. So devastating.\"\n",
    "result = classify_emotion(test1)\n",
    "print(f\"  '{test1[:50]}...'\")\n",
    "print(f\"  â†’ {result[1]} (label: {result[0]})\")\n",
    "\n",
    "test2 = \"GOOOAAL! France wins the World Cup!\"\n",
    "result = classify_emotion(test2)\n",
    "print(f\"\\n  '{test2}'\")\n",
    "print(f\"  â†’ {result[1]} (label: {result[0]})\")\n",
    "\n",
    "print(\"\\nTesting GoEmotions classification...\")\n",
    "test3 = \"This meme is hilarious, I can't stop laughing\"\n",
    "result = classify_goemotions_row(test3)\n",
    "print(f\"  '{test3}'\")\n",
    "print(f\"  â†’ crisis: {result[0]}, event_type: {result[1]}, informativeness: {result[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Identify Rows That Need Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows needing emotion classification (Crisis + Non-crisis)\n",
    "needs_emotion = df['emotion_label'].isna()\n",
    "emotion_indices = df[needs_emotion].index.tolist()\n",
    "\n",
    "# Identify GoEmotions rows needing crisis-related fields\n",
    "is_goemotions = df['source_dataset'] == 'GoEmotions'\n",
    "goemotions_indices = df[is_goemotions].index.tolist()\n",
    "\n",
    "print(f\"Rows needing emotion classification: {len(emotion_indices):,}\")\n",
    "print(f\"GoEmotions rows needing crisis fields: {len(goemotions_indices):,}\")\n",
    "print(f\"\\nTotal API calls needed: {len(emotion_indices) + len(goemotions_indices):,}\")\n",
    "\n",
    "# Cost estimate\n",
    "total_calls = len(emotion_indices) + len(goemotions_indices)\n",
    "est_cost = (total_calls * 200 * 0.10 / 1_000_000) + (total_calls * 30 * 0.40 / 1_000_000)\n",
    "print(f\"Estimated cost: ${est_cost:.2f} USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Progress Tracking Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint directory\n",
    "CHECKPOINT_DIR = Path('llm_labeling_checkpoints')\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "CHECKPOINT_FILE = CHECKPOINT_DIR / 'labeled_progress.csv'\n",
    "PROGRESS_FILE = CHECKPOINT_DIR / 'progress.json'\n",
    "\n",
    "def load_progress():\n",
    "    if PROGRESS_FILE.exists():\n",
    "        with open(PROGRESS_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {'emotion_last_idx': -1, 'goemotions_last_idx': -1}\n",
    "\n",
    "def save_progress(emotion_idx, goemotions_idx):\n",
    "    with open(PROGRESS_FILE, 'w') as f:\n",
    "        json.dump({\n",
    "            'emotion_last_idx': emotion_idx,\n",
    "            'goemotions_last_idx': goemotions_idx,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }, f)\n",
    "\n",
    "progress = load_progress()\n",
    "print(f\"Loaded progress: {progress}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Main Processing Loop - EMOTION CLASSIFICATION\n",
    "\n",
    "Fill `emotion_label` and `emotion_name` for Crisis + Non-crisis tweets (~43K rows)\n",
    "\n",
    "**Estimated time: 1-2 hours | Estimated cost: ~$1 USD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 100          # Save checkpoint every N rows\n",
    "RATE_LIMIT_DELAY = 0.1    # Seconds between API calls\n",
    "MAX_ROWS = None           # Set to a number for testing (e.g., 100), None for all\n",
    "\n",
    "# Get starting point from checkpoint\n",
    "start_idx = progress['emotion_last_idx'] + 1\n",
    "indices_to_process = emotion_indices[start_idx:]\n",
    "\n",
    "if MAX_ROWS:\n",
    "    indices_to_process = indices_to_process[:MAX_ROWS]\n",
    "\n",
    "print(f\"Emotion classification config:\")\n",
    "print(f\"  Start index: {start_idx}\")\n",
    "print(f\"  Rows to process: {len(indices_to_process):,}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process emotion classification\n",
    "errors = []\n",
    "processed = 0\n",
    "\n",
    "for i, idx in enumerate(tqdm(indices_to_process, desc=\"Classifying emotions\")):\n",
    "    text = df.at[idx, 'text']\n",
    "    \n",
    "    if pd.isna(text) or str(text).strip() == '':\n",
    "        continue\n",
    "    \n",
    "    emotion_label, emotion_name = classify_emotion(text)\n",
    "    \n",
    "    if emotion_label is not None:\n",
    "        df.at[idx, 'emotion_label'] = emotion_label\n",
    "        df.at[idx, 'emotion_name'] = emotion_name\n",
    "        processed += 1\n",
    "    else:\n",
    "        errors.append(idx)\n",
    "    \n",
    "    time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    if (i + 1) % BATCH_SIZE == 0:\n",
    "        save_progress(start_idx + i, progress['goemotions_last_idx'])\n",
    "        df.to_csv(CHECKPOINT_FILE, index=False)\n",
    "\n",
    "# Final save\n",
    "save_progress(start_idx + len(indices_to_process) - 1, progress['goemotions_last_idx'])\n",
    "df.to_csv(CHECKPOINT_FILE, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Emotion classification complete!\")\n",
    "print(f\"   Processed: {processed:,}\")\n",
    "print(f\"   Errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Main Processing Loop - GOEMOTIONS CRISIS FIELDS\n",
    "\n",
    "Fill `crisis_label`, `event_type`, `event_name`, `informativeness` for GoEmotions (~17K rows)\n",
    "\n",
    "**Estimated time: 30-60 minutes | Estimated cost: ~$0.50 USD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload progress\n",
    "progress = load_progress()\n",
    "\n",
    "start_idx = progress['goemotions_last_idx'] + 1\n",
    "indices_to_process = goemotions_indices[start_idx:]\n",
    "\n",
    "if MAX_ROWS:\n",
    "    indices_to_process = indices_to_process[:MAX_ROWS]\n",
    "\n",
    "print(f\"GoEmotions classification config:\")\n",
    "print(f\"  Start index: {start_idx}\")\n",
    "print(f\"  Rows to process: {len(indices_to_process):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process GoEmotions rows\n",
    "errors_goe = []\n",
    "processed_goe = 0\n",
    "\n",
    "for i, idx in enumerate(tqdm(indices_to_process, desc=\"Classifying GoEmotions\")):\n",
    "    text = df.at[idx, 'text']\n",
    "    \n",
    "    if pd.isna(text) or str(text).strip() == '':\n",
    "        continue\n",
    "    \n",
    "    crisis_label, event_type, event_name, informativeness = classify_goemotions_row(text)\n",
    "    \n",
    "    if crisis_label is not None:\n",
    "        df.at[idx, 'crisis_label'] = crisis_label\n",
    "        df.at[idx, 'event_type'] = event_type\n",
    "        df.at[idx, 'event_name'] = event_name\n",
    "        df.at[idx, 'informativeness'] = informativeness\n",
    "        processed_goe += 1\n",
    "    else:\n",
    "        errors_goe.append(idx)\n",
    "    \n",
    "    time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    if (i + 1) % BATCH_SIZE == 0:\n",
    "        save_progress(progress['emotion_last_idx'], start_idx + i)\n",
    "        df.to_csv(CHECKPOINT_FILE, index=False)\n",
    "\n",
    "# Final save\n",
    "save_progress(progress['emotion_last_idx'], start_idx + len(indices_to_process) - 1)\n",
    "df.to_csv(CHECKPOINT_FILE, index=False)\n",
    "\n",
    "print(f\"\\nâœ… GoEmotions classification complete!\")\n",
    "print(f\"   Processed: {processed_goe:,}\")\n",
    "print(f\"   Errors: {len(errors_goe)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Validation - Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"VALIDATION - After LLM Labeling\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nNull counts:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nEmotion distribution:\")\n",
    "print(df['emotion_name'].value_counts())\n",
    "\n",
    "print(f\"\\nCrisis label distribution:\")\n",
    "print(df['crisis_label'].value_counts())\n",
    "\n",
    "print(f\"\\nEvent type distribution:\")\n",
    "print(df['event_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Final Labeled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save final labeled dataset\nOUTPUT_PATH = 'master_training_data/master_training_data_v5_labelled.csv'\n\ndf.to_csv(OUTPUT_PATH, index=False)\n\nfile_size = Path(OUTPUT_PATH).stat().st_size / (1024**2)\n\nprint(\"=\" * 80)\nprint(\"FINAL LABELED DATASET SAVED\")\nprint(\"=\" * 80)\nprint(f\"\\nâœ… Saved to: {OUTPUT_PATH}\")\nprint(f\"   File size: {file_size:.2f} MB\")\nprint(f\"   Total rows: {len(df):,}\")\nprint(f\"\\nAll rows now have complete labels for BERT training!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create sample file\nSAMPLE_PATH = 'master_training_data/master_training_sample_v5_labelled.csv'\ndf_sample = df.sample(n=min(10000, len(df)), random_state=42)\ndf_sample.to_csv(SAMPLE_PATH, index=False)\n\nprint(f\"âœ… Created sample file: {SAMPLE_PATH}\")\nprint(f\"   Rows: {len(df_sample):,}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LLM LABELING COMPLETE - FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Statistics:\")\n",
    "print(f\"   Total rows: {len(df):,}\")\n",
    "print(f\"   Rows with emotion labels: {df['emotion_label'].notna().sum():,}\")\n",
    "print(f\"   Rows with crisis labels: {df['crisis_label'].notna().sum():,}\")\n",
    "\n",
    "print(f\"\\nðŸ“ Files Created:\")\n",
    "print(f\"   Main: {OUTPUT_PATH}\")\n",
    "print(f\"   Sample: {SAMPLE_PATH}\")\n",
    "\n",
    "print(f\"\\nâœ… Dataset is now ready for multi-task BERT training!\")\n",
    "print(f\"   - All rows have emotion_label and emotion_name\")\n",
    "print(f\"   - All rows have crisis_label\")\n",
    "print(f\"   - All rows have event_type and informativeness\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}