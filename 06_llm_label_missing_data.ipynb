{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Phase 5: LLM-Based Data Labeling\n## Fill Missing Values Using Gemini 2.0 Flash API\n\nThis notebook uses Google's Gemini 2.0 Flash to fill missing values in the master training dataset.\n\n### Strategy (per mentor's advice):\n- Process **one row at a time** for better accuracy\n- Each tweet gets its own API call (like sending 1 slide at a time to ChatGPT)\n- Save progress periodically to handle interruptions\n\n### What we're filling:\n\n| Source | Missing Columns | Rows |\n|--------|-----------------|------|\n| Crisis tweets | emotion_label, emotion_name | ~67K |\n| Non-crisis tweets | emotion_label, emotion_name | ~96K |\n| GoEmotions | crisis_label, event_type, event_name, informativeness | ~54K |\n\n### Estimated Cost: ~$5-8 USD (Gemini 2.0 Flash)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages if not already installed\n# !pip install google-generativeai python-dotenv tqdm\n\nimport pandas as pd\nimport numpy as np\nimport google.generativeai as genai\nimport json\nimport time\nimport os\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom datetime import datetime\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', 100)\n\nprint(\"âœ… Libraries loaded successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load API key from .env file\nGEMINI_API_KEY = os.getenv('GOOGLE_API_KEY')\n\nif not GEMINI_API_KEY or GEMINI_API_KEY == 'your_api_key_here':\n    print(\"âš ï¸  Please set your Gemini API key in the .env file!\")\n    print(\"   1. Open .env file in your project root\")\n    print(\"   2. Replace 'your_api_key_here' with your actual API key\")\n    print(\"   3. Get a key at: https://makersuite.google.com/app/apikey\")\nelse:\n    genai.configure(api_key=GEMINI_API_KEY)\n    print(\"âœ… Gemini API configured from .env file!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize the model\n# Options: \n#   - \"gemini-2.0-flash\" (recommended - good balance of speed/quality)\n#   - \"gemini-2.0-flash-lite\" (cheaper but lower accuracy)\n#   - \"gemini-1.5-flash\" (previous gen, also good)\nMODEL_NAME = \"gemini-2.0-flash\"\n\nmodel = genai.GenerativeModel(\n    model_name=MODEL_NAME,\n    generation_config={\n        \"temperature\": 0.1,  # Low temperature for consistent classification\n        \"top_p\": 0.95,\n        \"max_output_tokens\": 100,  # We only need short responses\n    }\n)\n\nprint(f\"âœ… Model initialized: {MODEL_NAME}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Master Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the master training dataset\n",
    "MASTER_PATH = 'master_training_data/master_training_data_v4.csv'\n",
    "\n",
    "df = pd.read_csv(MASTER_PATH)\n",
    "print(f\"âœ… Loaded {len(df):,} rows from {MASTER_PATH}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nNull counts:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with null text (can't classify empty text)\n",
    "null_text_count = df['text'].isna().sum()\n",
    "if null_text_count > 0:\n",
    "    print(f\"Removing {null_text_count} rows with null text...\")\n",
    "    df = df[df['text'].notna()].reset_index(drop=True)\n",
    "    print(f\"Remaining rows: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Classification Schema\n",
    "\n",
    "### 13 Emotion Categories (mapped from GoEmotions 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion mapping (label -> name)\n",
    "EMOTION_MAP = {\n",
    "    1: \"admiration\",\n",
    "    2: \"anger\",\n",
    "    3: \"annoyance\",\n",
    "    4: \"caring\",\n",
    "    5: \"confusion\",\n",
    "    6: \"curiosity\",\n",
    "    7: \"desire\",\n",
    "    8: \"disappointment\",\n",
    "    9: \"fear\",\n",
    "    10: \"gratitude\",\n",
    "    11: \"joy\",\n",
    "    12: \"amusement\",\n",
    "    13: \"neutral\"\n",
    "}\n",
    "\n",
    "# Reverse mapping (name -> label)\n",
    "EMOTION_NAME_TO_LABEL = {v: k for k, v in EMOTION_MAP.items()}\n",
    "\n",
    "# Informativeness labels (from CrisisLex)\n",
    "INFORMATIVENESS_LABELS = [\n",
    "    \"related_informative\",      # Crisis-related and informative\n",
    "    \"related_not_informative\",  # Crisis-related but not informative\n",
    "    \"not_related\"               # Not crisis-related\n",
    "]\n",
    "\n",
    "print(\"Emotion categories:\")\n",
    "for label, name in EMOTION_MAP.items():\n",
    "    print(f\"  {label}: {name}\")\n",
    "\n",
    "print(f\"\\nInformativeness labels: {INFORMATIVENESS_LABELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for classifying EMOTION (for Crisis/Non-crisis tweets)\n",
    "EMOTION_PROMPT_TEMPLATE = \"\"\"Classify the emotion in this tweet into exactly ONE of these 13 categories:\n",
    "1. admiration - respect, approval for someone/something\n",
    "2. anger - strong displeasure, hostility\n",
    "3. annoyance - mild irritation, frustration\n",
    "4. caring - concern, empathy for others\n",
    "5. confusion - uncertainty, bewilderment\n",
    "6. curiosity - desire to learn or know\n",
    "7. desire - wanting something\n",
    "8. disappointment - sadness from unmet expectations\n",
    "9. fear - anxiety, worry, being scared\n",
    "10. gratitude - thankfulness, appreciation\n",
    "11. joy - happiness, excitement, celebration\n",
    "12. amusement - finding something funny/entertaining\n",
    "13. neutral - no strong emotion, factual statement\n",
    "\n",
    "Tweet: \"{text}\"\n",
    "\n",
    "Respond with ONLY the emotion name (one word, lowercase). Nothing else.\"\"\"\n",
    "\n",
    "\n",
    "# Prompt for classifying GoEmotions data (crisis_label, event_type, informativeness)\n",
    "GOEMOTIONS_PROMPT_TEMPLATE = \"\"\"Analyze this Reddit comment and determine:\n",
    "1. Is it related to a crisis/disaster/emergency? (yes/no)\n",
    "2. If crisis-related, what type? (hurricane, earthquake, flood, wildfire, terrorism, shooting, pandemic, other_crisis)\n",
    "   If NOT crisis-related, use: general_discussion\n",
    "3. Informativeness: \n",
    "   - \"related_informative\" = discusses crisis with useful info\n",
    "   - \"related_not_informative\" = mentions crisis but no useful info\n",
    "   - \"not_related\" = not about any crisis\n",
    "\n",
    "Comment: \"{text}\"\n",
    "\n",
    "Respond in this EXACT format (3 lines):\n",
    "crisis: yes or no\n",
    "event_type: <type>\n",
    "informativeness: <label>\"\"\"\n",
    "\n",
    "print(\"âœ… Prompt templates defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_emotion(text, max_retries=3):\n",
    "    \"\"\"\n",
    "    Classify the emotion of a tweet using Gemini.\n",
    "    Returns: (emotion_label, emotion_name) or (None, None) on failure\n",
    "    \"\"\"\n",
    "    prompt = EMOTION_PROMPT_TEMPLATE.format(text=text[:500])  # Truncate long texts\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            emotion_name = response.text.strip().lower()\n",
    "            \n",
    "            # Validate response\n",
    "            if emotion_name in EMOTION_NAME_TO_LABEL:\n",
    "                emotion_label = EMOTION_NAME_TO_LABEL[emotion_name]\n",
    "                return emotion_label, emotion_name\n",
    "            else:\n",
    "                # Try to match partial response\n",
    "                for name in EMOTION_NAME_TO_LABEL:\n",
    "                    if name in emotion_name:\n",
    "                        return EMOTION_NAME_TO_LABEL[name], name\n",
    "                # Default to neutral if unrecognized\n",
    "                return 13, \"neutral\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "            else:\n",
    "                print(f\"Error classifying: {str(e)[:50]}\")\n",
    "                return None, None\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "\n",
    "def classify_goemotions_row(text, max_retries=3):\n",
    "    \"\"\"\n",
    "    Classify a GoEmotions comment for crisis-related fields.\n",
    "    Returns: (crisis_label, event_type, event_name, informativeness) or Nones on failure\n",
    "    \"\"\"\n",
    "    prompt = GOEMOTIONS_PROMPT_TEMPLATE.format(text=text[:500])\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            lines = response.text.strip().lower().split('\\n')\n",
    "            \n",
    "            # Parse response\n",
    "            crisis_label = 0\n",
    "            event_type = \"general_discussion\"\n",
    "            informativeness = \"not_related\"\n",
    "            \n",
    "            for line in lines:\n",
    "                if 'crisis:' in line:\n",
    "                    crisis_label = 1 if 'yes' in line else 0\n",
    "                elif 'event_type:' in line:\n",
    "                    event_type = line.split(':')[1].strip()\n",
    "                elif 'informativeness:' in line:\n",
    "                    info = line.split(':')[1].strip()\n",
    "                    # Normalize informativeness\n",
    "                    if 'not_related' in info or 'not related' in info:\n",
    "                        informativeness = 'not_related'\n",
    "                    elif 'not_informative' in info or 'not informative' in info:\n",
    "                        informativeness = 'related_not_informative'\n",
    "                    elif 'informative' in info:\n",
    "                        informativeness = 'related_informative'\n",
    "            \n",
    "            # Generate event_name from event_type\n",
    "            event_name = event_type if event_type != \"general_discussion\" else \"general_discussion\"\n",
    "            \n",
    "            return crisis_label, event_type, event_name, informativeness\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "            else:\n",
    "                print(f\"Error classifying: {str(e)[:50]}\")\n",
    "                return None, None, None, None\n",
    "    \n",
    "    return None, None, None, None\n",
    "\n",
    "\n",
    "print(\"âœ… Classification functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Classification (Single Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test emotion classification on a crisis tweet\n",
    "test_crisis_tweet = \"Pray for the victims of the hurricane. So devastating to see the destruction.\"\n",
    "emotion_label, emotion_name = classify_emotion(test_crisis_tweet)\n",
    "print(f\"Crisis tweet: '{test_crisis_tweet}'\")\n",
    "print(f\"  â†’ Emotion: {emotion_name} (label: {emotion_label})\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test emotion classification on a non-crisis tweet\n",
    "test_sports_tweet = \"GOOOAAL! What an amazing match! France wins the World Cup!\"\n",
    "emotion_label, emotion_name = classify_emotion(test_sports_tweet)\n",
    "print(f\"Sports tweet: '{test_sports_tweet}'\")\n",
    "print(f\"  â†’ Emotion: {emotion_name} (label: {emotion_label})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GoEmotions classification\n",
    "test_goemotions_1 = \"This is hilarious, I can't stop laughing at this meme\"\n",
    "result = classify_goemotions_row(test_goemotions_1)\n",
    "print(f\"GoEmotions (non-crisis): '{test_goemotions_1}'\")\n",
    "print(f\"  â†’ crisis_label: {result[0]}, event_type: {result[1]}, informativeness: {result[3]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "test_goemotions_2 = \"The earthquake in Japan was terrifying, I hope everyone is safe\"\n",
    "result = classify_goemotions_row(test_goemotions_2)\n",
    "print(f\"GoEmotions (crisis-related): '{test_goemotions_2}'\")\n",
    "print(f\"  â†’ crisis_label: {result[0]}, event_type: {result[1]}, informativeness: {result[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Identify Rows That Need Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows needing emotion classification (Crisis + Non-crisis)\n",
    "needs_emotion = df['emotion_label'].isna()\n",
    "emotion_indices = df[needs_emotion].index.tolist()\n",
    "\n",
    "# Identify GoEmotions rows needing crisis-related fields\n",
    "is_goemotions = df['source_dataset'] == 'GoEmotions'\n",
    "goemotions_indices = df[is_goemotions].index.tolist()\n",
    "\n",
    "print(f\"Rows needing emotion classification: {len(emotion_indices):,}\")\n",
    "print(f\"GoEmotions rows needing crisis fields: {len(goemotions_indices):,}\")\n",
    "print(f\"\\nTotal API calls needed: {len(emotion_indices) + len(goemotions_indices):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Progress Tracking Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint directory\n",
    "CHECKPOINT_DIR = Path('llm_labeling_checkpoints')\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Checkpoint file paths\n",
    "EMOTION_CHECKPOINT = CHECKPOINT_DIR / 'emotion_progress.csv'\n",
    "GOEMOTIONS_CHECKPOINT = CHECKPOINT_DIR / 'goemotions_progress.csv'\n",
    "PROGRESS_FILE = CHECKPOINT_DIR / 'progress.json'\n",
    "\n",
    "def load_progress():\n",
    "    \"\"\"Load progress from checkpoint.\"\"\"\n",
    "    if PROGRESS_FILE.exists():\n",
    "        with open(PROGRESS_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {'emotion_last_idx': -1, 'goemotions_last_idx': -1}\n",
    "\n",
    "def save_progress(emotion_idx, goemotions_idx):\n",
    "    \"\"\"Save progress to checkpoint.\"\"\"\n",
    "    with open(PROGRESS_FILE, 'w') as f:\n",
    "        json.dump({\n",
    "            'emotion_last_idx': emotion_idx,\n",
    "            'goemotions_last_idx': goemotions_idx,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }, f)\n",
    "\n",
    "progress = load_progress()\n",
    "print(f\"Loaded progress: {progress}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Main Processing Loop - EMOTION CLASSIFICATION\n",
    "\n",
    "Process Crisis + Non-crisis tweets to fill `emotion_label` and `emotion_name`.\n",
    "\n",
    "**âš ï¸ This will make ~162K API calls. Estimated time: 4-8 hours (with rate limiting)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 100          # Save checkpoint every N rows\n",
    "RATE_LIMIT_DELAY = 0.1    # Seconds between API calls (to avoid rate limits)\n",
    "MAX_ROWS = None           # Set to a number to limit rows (e.g., 1000 for testing), None for all\n",
    "\n",
    "# Get starting point from checkpoint\n",
    "start_idx = progress['emotion_last_idx'] + 1\n",
    "indices_to_process = emotion_indices[start_idx:]\n",
    "\n",
    "if MAX_ROWS:\n",
    "    indices_to_process = indices_to_process[:MAX_ROWS]\n",
    "\n",
    "print(f\"Starting emotion classification...\")\n",
    "print(f\"  Start index: {start_idx}\")\n",
    "print(f\"  Rows to process: {len(indices_to_process):,}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Rate limit delay: {RATE_LIMIT_DELAY}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process emotion classification\n",
    "errors = []\n",
    "processed = 0\n",
    "\n",
    "for i, idx in enumerate(tqdm(indices_to_process, desc=\"Classifying emotions\")):\n",
    "    text = df.at[idx, 'text']\n",
    "    \n",
    "    # Skip if text is empty/null\n",
    "    if pd.isna(text) or text.strip() == '':\n",
    "        continue\n",
    "    \n",
    "    # Classify emotion\n",
    "    emotion_label, emotion_name = classify_emotion(text)\n",
    "    \n",
    "    if emotion_label is not None:\n",
    "        df.at[idx, 'emotion_label'] = emotion_label\n",
    "        df.at[idx, 'emotion_name'] = emotion_name\n",
    "        processed += 1\n",
    "    else:\n",
    "        errors.append(idx)\n",
    "    \n",
    "    # Rate limiting\n",
    "    time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    # Save checkpoint every BATCH_SIZE rows\n",
    "    if (i + 1) % BATCH_SIZE == 0:\n",
    "        save_progress(start_idx + i, progress['goemotions_last_idx'])\n",
    "        # Save intermediate results\n",
    "        df.to_csv(EMOTION_CHECKPOINT, index=False)\n",
    "        print(f\"\\n  Checkpoint saved at row {start_idx + i + 1}\")\n",
    "\n",
    "# Final save\n",
    "save_progress(start_idx + len(indices_to_process) - 1, progress['goemotions_last_idx'])\n",
    "df.to_csv(EMOTION_CHECKPOINT, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Emotion classification complete!\")\n",
    "print(f\"   Processed: {processed:,}\")\n",
    "print(f\"   Errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Main Processing Loop - GOEMOTIONS CRISIS FIELDS\n",
    "\n",
    "Process GoEmotions rows to fill `crisis_label`, `event_type`, `event_name`, `informativeness`.\n",
    "\n",
    "**âš ï¸ This will make ~54K API calls. Estimated time: 1-3 hours (with rate limiting)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload progress\n",
    "progress = load_progress()\n",
    "\n",
    "# Get starting point\n",
    "start_idx = progress['goemotions_last_idx'] + 1\n",
    "indices_to_process = goemotions_indices[start_idx:]\n",
    "\n",
    "if MAX_ROWS:\n",
    "    indices_to_process = indices_to_process[:MAX_ROWS]\n",
    "\n",
    "print(f\"Starting GoEmotions crisis classification...\")\n",
    "print(f\"  Start index: {start_idx}\")\n",
    "print(f\"  Rows to process: {len(indices_to_process):,}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process GoEmotions rows\n",
    "errors_goe = []\n",
    "processed_goe = 0\n",
    "\n",
    "for i, idx in enumerate(tqdm(indices_to_process, desc=\"Classifying GoEmotions\")):\n",
    "    text = df.at[idx, 'text']\n",
    "    \n",
    "    # Skip if text is empty/null\n",
    "    if pd.isna(text) or text.strip() == '':\n",
    "        continue\n",
    "    \n",
    "    # Classify crisis fields\n",
    "    crisis_label, event_type, event_name, informativeness = classify_goemotions_row(text)\n",
    "    \n",
    "    if crisis_label is not None:\n",
    "        df.at[idx, 'crisis_label'] = crisis_label\n",
    "        df.at[idx, 'event_type'] = event_type\n",
    "        df.at[idx, 'event_name'] = event_name\n",
    "        df.at[idx, 'informativeness'] = informativeness\n",
    "        processed_goe += 1\n",
    "    else:\n",
    "        errors_goe.append(idx)\n",
    "    \n",
    "    # Rate limiting\n",
    "    time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    # Save checkpoint every BATCH_SIZE rows\n",
    "    if (i + 1) % BATCH_SIZE == 0:\n",
    "        save_progress(progress['emotion_last_idx'], start_idx + i)\n",
    "        df.to_csv(GOEMOTIONS_CHECKPOINT, index=False)\n",
    "        print(f\"\\n  Checkpoint saved at row {start_idx + i + 1}\")\n",
    "\n",
    "# Final save\n",
    "save_progress(progress['emotion_last_idx'], start_idx + len(indices_to_process) - 1)\n",
    "df.to_csv(GOEMOTIONS_CHECKPOINT, index=False)\n",
    "\n",
    "print(f\"\\nâœ… GoEmotions classification complete!\")\n",
    "print(f\"   Processed: {processed_goe:,}\")\n",
    "print(f\"   Errors: {len(errors_goe)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Validation - Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"VALIDATION - After LLM Labeling\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nNull counts:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nEmotion distribution:\")\n",
    "print(df['emotion_name'].value_counts())\n",
    "\n",
    "print(f\"\\nCrisis label distribution:\")\n",
    "print(df['crisis_label'].value_counts())\n",
    "\n",
    "print(f\"\\nEvent type distribution:\")\n",
    "print(df['event_type'].value_counts())\n",
    "\n",
    "print(f\"\\nInformativeness distribution:\")\n",
    "print(df['informativeness'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample results\n",
    "print(\"Sample results - Crisis tweets with new emotion labels:\")\n",
    "crisis_sample = df[df['source_dataset'].isin(['humaid', 'crisislex'])].head(5)\n",
    "display(crisis_sample[['text', 'emotion_name', 'source_dataset', 'crisis_label']])\n",
    "\n",
    "print(\"\\nSample results - GoEmotions with new crisis fields:\")\n",
    "goe_sample = df[df['source_dataset'] == 'GoEmotions'].head(5)\n",
    "display(goe_sample[['text', 'emotion_name', 'crisis_label', 'event_type', 'informativeness']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Final Labeled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final labeled dataset\n",
    "OUTPUT_PATH = 'master_training_data/master_training_data_v5_labeled.csv'\n",
    "\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "file_size = Path(OUTPUT_PATH).stat().st_size / (1024**2)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL LABELED DATASET SAVED\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nâœ… Saved to: {OUTPUT_PATH}\")\n",
    "print(f\"   File size: {file_size:.2f} MB\")\n",
    "print(f\"   Total rows: {len(df):,}\")\n",
    "print(f\"\\nAll rows now have complete labels for BERT training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smaller sample for testing\n",
    "SAMPLE_PATH = 'master_training_data/master_training_sample_10k_labeled.csv'\n",
    "df_sample = df.sample(n=10000, random_state=42)\n",
    "df_sample.to_csv(SAMPLE_PATH, index=False)\n",
    "\n",
    "print(f\"âœ… Created sample file: {SAMPLE_PATH}\")\n",
    "print(f\"   Rows: {len(df_sample):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LLM LABELING COMPLETE - FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Statistics:\")\n",
    "print(f\"   Total rows: {len(df):,}\")\n",
    "print(f\"   Rows with emotion labels: {df['emotion_label'].notna().sum():,}\")\n",
    "print(f\"   Rows with crisis labels: {df['crisis_label'].notna().sum():,}\")\n",
    "\n",
    "print(f\"\\nðŸ“ Files Created:\")\n",
    "print(f\"   Main: {OUTPUT_PATH}\")\n",
    "print(f\"   Sample: {SAMPLE_PATH}\")\n",
    "\n",
    "print(f\"\\nðŸ’° Estimated Cost:\")\n",
    "total_calls = len(emotion_indices) + len(goemotions_indices)\n",
    "est_cost = (total_calls * 200 * 0.075 / 1_000_000) + (total_calls * 30 * 0.30 / 1_000_000)\n",
    "print(f\"   API calls: {total_calls:,}\")\n",
    "print(f\"   Estimated: ${est_cost:.2f} USD\")\n",
    "\n",
    "print(f\"\\nâœ… Dataset is now ready for multi-task BERT training!\")\n",
    "print(f\"   - All rows have emotion_label and emotion_name\")\n",
    "print(f\"   - All rows have crisis_label\")\n",
    "print(f\"   - All rows have event_type and informativeness\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}