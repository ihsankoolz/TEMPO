{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: LLM-Based Data Labeling\n",
    "## Fill Missing Values Using Gemini 2.0 Flash API\n",
    "\n",
    "This notebook uses Google's Gemini 2.0 Flash to fill missing values in the master training dataset (v5).\n",
    "\n",
    "### Prerequisites:\n",
    "- Run notebook 05 first to create `master_training_data_v5.csv` (60K stratified rows)\n",
    "\n",
    "### What we're filling:\n",
    "\n",
    "| Source | Missing Columns | Rows |\n",
    "|--------|-----------------|------|\n",
    "| Crisis tweets | emotion_label, emotion_name | ~25K |\n",
    "| Non-crisis tweets | emotion_label, emotion_name | ~18K |\n",
    "| GoEmotions | crisis_label, event_type, event_name, informativeness | ~17K |\n",
    "\n",
    "### Strategy (per mentor's advice):\n",
    "- Process **one row at a time** for better accuracy\n",
    "- Each tweet gets its own API call\n",
    "- Save progress periodically to handle interruptions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if not already installed\n",
    "# !pip install google-generativeai python-dotenv tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"âœ… Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gemini API configured from .env file!\n"
     ]
    }
   ],
   "source": [
    "# Load API key from .env file\n",
    "GEMINI_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if not GEMINI_API_KEY or GEMINI_API_KEY == 'your_api_key_here':\n",
    "    print(\"âš ï¸  Please set your Gemini API key in the .env file!\")\n",
    "    print(\"   1. Open .env file in your project root\")\n",
    "    print(\"   2. Replace 'your_api_key_here' with your actual API key\")\n",
    "    print(\"   3. Get a key at: https://makersuite.google.com/app/apikey\")\n",
    "else:\n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    print(\"âœ… Gemini API configured from .env file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model initialized: gemini-2.0-flash\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "# Options: \n",
    "#   - \"gemini-2.0-flash\" (recommended - good balance of speed/quality)\n",
    "#   - \"gemini-2.0-flash-lite\" (cheaper but lower accuracy)\n",
    "#   - \"gemini-1.5-flash\" (previous gen, also good)\n",
    "MODEL_NAME = \"gemini-2.0-flash\"\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=MODEL_NAME,\n",
    "    generation_config={\n",
    "        \"temperature\": 0.1,  # Low temperature for consistent classification\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_output_tokens\": 100,  # We only need short responses\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"âœ… Model initialized: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Master Dataset (v5 - 60K stratified rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 52,767 rows from master_training_data/master_training_data_v5.csv\n",
      "\n",
      "Columns: ['text', 'emotion_label', 'emotion_name', 'source_dataset', 'crisis_label', 'event_type', 'event_name', 'informativeness']\n",
      "\n",
      "Null counts:\n",
      "text                   4\n",
      "emotion_label      38111\n",
      "emotion_name       38111\n",
      "source_dataset         0\n",
      "crisis_label       14656\n",
      "event_type         14656\n",
      "event_name         14656\n",
      "informativeness    40247\n",
      "dtype: int64\n",
      "\n",
      "Source distribution:\n",
      "source_dataset\n",
      "GoEmotions         14656\n",
      "crisislex          12733\n",
      "humaid              8122\n",
      "us_election         2571\n",
      "game_of_thrones     2571\n",
      "worldcup_2018       2571\n",
      "tokyo_olympics      2571\n",
      "coachella           2571\n",
      "fifa_worldcup       2571\n",
      "music_concerts      1830\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the stratified master training dataset from notebook 05\n",
    "MASTER_PATH = 'master_training_data/master_training_data_v5.csv'\n",
    "\n",
    "df = pd.read_csv(MASTER_PATH)\n",
    "print(f\"âœ… Loaded {len(df):,} rows from {MASTER_PATH}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nNull counts:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nSource distribution:\")\n",
    "print(df['source_dataset'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 4 rows with null text...\n",
      "Remaining rows: 52,763\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with null text (can't classify empty text)\n",
    "null_text_count = df['text'].isna().sum()\n",
    "if null_text_count > 0:\n",
    "    print(f\"Removing {null_text_count} rows with null text...\")\n",
    "    df = df[df['text'].notna()].reset_index(drop=True)\n",
    "    print(f\"Remaining rows: {len(df):,}\")\n",
    "else:\n",
    "    print(\"âœ… No null text rows found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Classification Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Emotion categories:\n",
      "  1: admiration\n",
      "  2: anger\n",
      "  3: annoyance\n",
      "  4: caring\n",
      "  5: confusion\n",
      "  6: curiosity\n",
      "  7: desire\n",
      "  8: disappointment\n",
      "  9: fear\n",
      "  10: gratitude\n",
      "  11: joy\n",
      "  12: amusement\n",
      "  13: neutral\n"
     ]
    }
   ],
   "source": [
    "# Emotion mapping (label -> name)\n",
    "EMOTION_MAP = {\n",
    "    1: \"admiration\",\n",
    "    2: \"anger\",\n",
    "    3: \"annoyance\",\n",
    "    4: \"caring\",\n",
    "    5: \"confusion\",\n",
    "    6: \"curiosity\",\n",
    "    7: \"desire\",\n",
    "    8: \"disappointment\",\n",
    "    9: \"fear\",\n",
    "    10: \"gratitude\",\n",
    "    11: \"joy\",\n",
    "    12: \"amusement\",\n",
    "    13: \"neutral\"\n",
    "}\n",
    "\n",
    "# Reverse mapping (name -> label)\n",
    "EMOTION_NAME_TO_LABEL = {v: k for k, v in EMOTION_MAP.items()}\n",
    "\n",
    "# Informativeness labels (from CrisisLex)\n",
    "INFORMATIVENESS_LABELS = [\n",
    "    \"related_informative\",\n",
    "    \"related_not_informative\",\n",
    "    \"not_related\"\n",
    "]\n",
    "\n",
    "print(\"13 Emotion categories:\")\n",
    "for label, name in EMOTION_MAP.items():\n",
    "    print(f\"  {label}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prompt templates defined\n"
     ]
    }
   ],
   "source": [
    "# Prompt for classifying EMOTION (for Crisis/Non-crisis tweets)\n",
    "EMOTION_PROMPT_TEMPLATE = \"\"\"Classify the emotion in this tweet into exactly ONE of these 13 categories:\n",
    "1. admiration - respect, approval for someone/something\n",
    "2. anger - strong displeasure, hostility\n",
    "3. annoyance - mild irritation, frustration\n",
    "4. caring - concern, empathy for others\n",
    "5. confusion - uncertainty, bewilderment\n",
    "6. curiosity - desire to learn or know\n",
    "7. desire - wanting something\n",
    "8. disappointment - sadness from unmet expectations\n",
    "9. fear - anxiety, worry, being scared\n",
    "10. gratitude - thankfulness, appreciation\n",
    "11. joy - happiness, excitement, celebration\n",
    "12. amusement - finding something funny/entertaining\n",
    "13. neutral - no strong emotion, factual statement\n",
    "\n",
    "Tweet: \"{text}\"\n",
    "\n",
    "Respond with ONLY the emotion name (one word, lowercase). Nothing else.\"\"\"\n",
    "\n",
    "\n",
    "# Prompt for classifying GoEmotions data (crisis_label, event_type, informativeness)\n",
    "GOEMOTIONS_PROMPT_TEMPLATE = \"\"\"Analyze this Reddit comment and determine:\n",
    "1. Is it related to a crisis/disaster/emergency? (yes/no)\n",
    "2. If crisis-related, what type? (hurricane, earthquake, flood, wildfire, terrorism, shooting, pandemic, other_crisis)\n",
    "   If NOT crisis-related, use: general_discussion\n",
    "3. Informativeness: \n",
    "   - \"related_informative\" = discusses crisis with useful info\n",
    "   - \"related_not_informative\" = mentions crisis but no useful info\n",
    "   - \"not_related\" = not about any crisis\n",
    "\n",
    "Comment: \"{text}\"\n",
    "\n",
    "Respond in this EXACT format (3 lines):\n",
    "crisis: yes or no\n",
    "event_type: <type>\n",
    "informativeness: <label>\"\"\"\n",
    "\n",
    "print(\"âœ… Prompt templates defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classification functions defined\n"
     ]
    }
   ],
   "source": [
    "def classify_emotion(text, max_retries=3):\n",
    "    \"\"\"Classify the emotion of a tweet using Gemini.\"\"\"\n",
    "    prompt = EMOTION_PROMPT_TEMPLATE.format(text=text[:500])\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            emotion_name = response.text.strip().lower()\n",
    "            \n",
    "            if emotion_name in EMOTION_NAME_TO_LABEL:\n",
    "                return EMOTION_NAME_TO_LABEL[emotion_name], emotion_name\n",
    "            else:\n",
    "                for name in EMOTION_NAME_TO_LABEL:\n",
    "                    if name in emotion_name:\n",
    "                        return EMOTION_NAME_TO_LABEL[name], name\n",
    "                return 13, \"neutral\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "            else:\n",
    "                print(f\"Error: {str(e)[:50]}\")\n",
    "                return None, None\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def classify_goemotions_row(text, max_retries=3):\n",
    "    \"\"\"Classify a GoEmotions comment for crisis-related fields.\"\"\"\n",
    "    prompt = GOEMOTIONS_PROMPT_TEMPLATE.format(text=text[:500])\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            lines = response.text.strip().lower().split('\\n')\n",
    "            \n",
    "            crisis_label = 0\n",
    "            event_type = \"general_discussion\"\n",
    "            informativeness = \"not_related\"\n",
    "            \n",
    "            for line in lines:\n",
    "                if 'crisis:' in line:\n",
    "                    crisis_label = 1 if 'yes' in line else 0\n",
    "                elif 'event_type:' in line:\n",
    "                    event_type = line.split(':')[1].strip()\n",
    "                elif 'informativeness:' in line:\n",
    "                    info = line.split(':')[1].strip()\n",
    "                    if 'not_related' in info or 'not related' in info:\n",
    "                        informativeness = 'not_related'\n",
    "                    elif 'not_informative' in info:\n",
    "                        informativeness = 'related_not_informative'\n",
    "                    elif 'informative' in info:\n",
    "                        informativeness = 'related_informative'\n",
    "            \n",
    "            event_name = event_type\n",
    "            return crisis_label, event_type, event_name, informativeness\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "            else:\n",
    "                print(f\"Error: {str(e)[:50]}\")\n",
    "                return None, None, None, None\n",
    "    return None, None, None, None\n",
    "\n",
    "print(\"âœ… Classification functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Classification (Verify API works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing emotion classification...\n",
      "  'Pray for the victims of the hurricane. So devastat...'\n",
      "  â†’ caring (label: 4)\n",
      "\n",
      "  'GOOOAAL! France wins the World Cup!'\n",
      "  â†’ joy (label: 11)\n",
      "\n",
      "Testing GoEmotions classification...\n",
      "  'This meme is hilarious, I can't stop laughing'\n",
      "  â†’ crisis: 0, event_type: general_discussion, informativeness: not_related\n"
     ]
    }
   ],
   "source": [
    "# Test emotion classification\n",
    "print(\"Testing emotion classification...\")\n",
    "test1 = \"Pray for the victims of the hurricane. So devastating.\"\n",
    "result = classify_emotion(test1)\n",
    "print(f\"  '{test1[:50]}...'\")\n",
    "print(f\"  â†’ {result[1]} (label: {result[0]})\")\n",
    "\n",
    "test2 = \"GOOOAAL! France wins the World Cup!\"\n",
    "result = classify_emotion(test2)\n",
    "print(f\"\\n  '{test2}'\")\n",
    "print(f\"  â†’ {result[1]} (label: {result[0]})\")\n",
    "\n",
    "print(\"\\nTesting GoEmotions classification...\")\n",
    "test3 = \"This meme is hilarious, I can't stop laughing\"\n",
    "result = classify_goemotions_row(test3)\n",
    "print(f\"  '{test3}'\")\n",
    "print(f\"  â†’ crisis: {result[0]}, event_type: {result[1]}, informativeness: {result[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Identify Rows That Need Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows needing emotion classification: 38,107\n",
      "GoEmotions rows needing crisis fields: 14,656\n",
      "\n",
      "Total API calls needed: 52,763\n",
      "Estimated cost: $1.69 USD\n"
     ]
    }
   ],
   "source": [
    "# Identify rows needing emotion classification (Crisis + Non-crisis)\n",
    "needs_emotion = df['emotion_label'].isna()\n",
    "emotion_indices = df[needs_emotion].index.tolist()\n",
    "\n",
    "# Identify GoEmotions rows needing crisis-related fields\n",
    "is_goemotions = df['source_dataset'] == 'GoEmotions'\n",
    "goemotions_indices = df[is_goemotions].index.tolist()\n",
    "\n",
    "print(f\"Rows needing emotion classification: {len(emotion_indices):,}\")\n",
    "print(f\"GoEmotions rows needing crisis fields: {len(goemotions_indices):,}\")\n",
    "print(f\"\\nTotal API calls needed: {len(emotion_indices) + len(goemotions_indices):,}\")\n",
    "\n",
    "# Cost estimate\n",
    "total_calls = len(emotion_indices) + len(goemotions_indices)\n",
    "est_cost = (total_calls * 200 * 0.10 / 1_000_000) + (total_calls * 30 * 0.40 / 1_000_000)\n",
    "print(f\"Estimated cost: ${est_cost:.2f} USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Progress Tracking Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded progress: {'emotion_last_idx': -1, 'goemotions_last_idx': -1}\n"
     ]
    }
   ],
   "source": [
    "# Create checkpoint directory\n",
    "CHECKPOINT_DIR = Path('llm_labeling_checkpoints')\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "CHECKPOINT_FILE = CHECKPOINT_DIR / 'labeled_progress.csv'\n",
    "PROGRESS_FILE = CHECKPOINT_DIR / 'progress.json'\n",
    "\n",
    "def load_progress():\n",
    "    if PROGRESS_FILE.exists():\n",
    "        with open(PROGRESS_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {'emotion_last_idx': -1, 'goemotions_last_idx': -1}\n",
    "\n",
    "def save_progress(emotion_idx, goemotions_idx):\n",
    "    with open(PROGRESS_FILE, 'w') as f:\n",
    "        json.dump({\n",
    "            'emotion_last_idx': emotion_idx,\n",
    "            'goemotions_last_idx': goemotions_idx,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }, f)\n",
    "\n",
    "progress = load_progress()\n",
    "print(f\"Loaded progress: {progress}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Main Processing Loop - EMOTION CLASSIFICATION\n",
    "\n",
    "Fill `emotion_label` and `emotion_name` for Crisis + Non-crisis tweets (~43K rows)\n",
    "\n",
    "**Estimated time: 1-2 hours | Estimated cost: ~$1 USD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion classification config:\n",
      "  Start index: 0\n",
      "  Rows to process: 38,107\n",
      "  Batch size: 100\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 100          # Save checkpoint every N rows\n",
    "RATE_LIMIT_DELAY = 0.1    # Seconds between API calls\n",
    "MAX_ROWS = None           # Set to a number for testing (e.g., 100), None for all\n",
    "\n",
    "# Get starting point from checkpoint\n",
    "start_idx = progress['emotion_last_idx'] + 1\n",
    "indices_to_process = emotion_indices[start_idx:]\n",
    "\n",
    "if MAX_ROWS:\n",
    "    indices_to_process = indices_to_process[:MAX_ROWS]\n",
    "\n",
    "print(f\"Emotion classification config:\")\n",
    "print(f\"  Start index: {start_idx}\")\n",
    "print(f\"  Rows to process: {len(indices_to_process):,}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying emotions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38107/38107 [9:13:40<00:00,  1.15it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Emotion classification complete!\n",
      "   Processed: 38,107\n",
      "   Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process emotion classification\n",
    "errors = []\n",
    "processed = 0\n",
    "\n",
    "for i, idx in enumerate(tqdm(indices_to_process, desc=\"Classifying emotions\")):\n",
    "    text = df.at[idx, 'text']\n",
    "    \n",
    "    if pd.isna(text) or str(text).strip() == '':\n",
    "        continue\n",
    "    \n",
    "    emotion_label, emotion_name = classify_emotion(text)\n",
    "    \n",
    "    if emotion_label is not None:\n",
    "        df.at[idx, 'emotion_label'] = emotion_label\n",
    "        df.at[idx, 'emotion_name'] = emotion_name\n",
    "        processed += 1\n",
    "    else:\n",
    "        errors.append(idx)\n",
    "    \n",
    "    time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    if (i + 1) % BATCH_SIZE == 0:\n",
    "        save_progress(start_idx + i, progress['goemotions_last_idx'])\n",
    "        df.to_csv(CHECKPOINT_FILE, index=False)\n",
    "\n",
    "# Final save\n",
    "save_progress(start_idx + len(indices_to_process) - 1, progress['goemotions_last_idx'])\n",
    "df.to_csv(CHECKPOINT_FILE, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Emotion classification complete!\")\n",
    "print(f\"   Processed: {processed:,}\")\n",
    "print(f\"   Errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Main Processing Loop - GOEMOTIONS CRISIS FIELDS\n",
    "\n",
    "Fill `crisis_label`, `event_type`, `event_name`, `informativeness` for GoEmotions (~17K rows)\n",
    "\n",
    "**Estimated time: 30-60 minutes | Estimated cost: ~$0.50 USD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoEmotions classification config:\n",
      "  Start index: 0\n",
      "  Rows to process: 14,656\n"
     ]
    }
   ],
   "source": [
    "# Reload progress\n",
    "progress = load_progress()\n",
    "\n",
    "start_idx = progress['goemotions_last_idx'] + 1\n",
    "indices_to_process = goemotions_indices[start_idx:]\n",
    "\n",
    "if MAX_ROWS:\n",
    "    indices_to_process = indices_to_process[:MAX_ROWS]\n",
    "\n",
    "print(f\"GoEmotions classification config:\")\n",
    "print(f\"  Start index: {start_idx}\")\n",
    "print(f\"  Rows to process: {len(indices_to_process):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying GoEmotions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14656/14656 [8:24:05<00:00,  2.06s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… GoEmotions classification complete!\n",
      "   Processed: 14,656\n",
      "   Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process GoEmotions rows\n",
    "errors_goe = []\n",
    "processed_goe = 0\n",
    "\n",
    "for i, idx in enumerate(tqdm(indices_to_process, desc=\"Classifying GoEmotions\")):\n",
    "    text = df.at[idx, 'text']\n",
    "    \n",
    "    if pd.isna(text) or str(text).strip() == '':\n",
    "        continue\n",
    "    \n",
    "    crisis_label, event_type, event_name, informativeness = classify_goemotions_row(text)\n",
    "    \n",
    "    if crisis_label is not None:\n",
    "        df.at[idx, 'crisis_label'] = crisis_label\n",
    "        df.at[idx, 'event_type'] = event_type\n",
    "        df.at[idx, 'event_name'] = event_name\n",
    "        df.at[idx, 'informativeness'] = informativeness\n",
    "        processed_goe += 1\n",
    "    else:\n",
    "        errors_goe.append(idx)\n",
    "    \n",
    "    time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    if (i + 1) % BATCH_SIZE == 0:\n",
    "        save_progress(progress['emotion_last_idx'], start_idx + i)\n",
    "        df.to_csv(CHECKPOINT_FILE, index=False)\n",
    "\n",
    "# Final save\n",
    "save_progress(progress['emotion_last_idx'], start_idx + len(indices_to_process) - 1)\n",
    "df.to_csv(CHECKPOINT_FILE, index=False)\n",
    "\n",
    "print(f\"\\nâœ… GoEmotions classification complete!\")\n",
    "print(f\"   Processed: {processed_goe:,}\")\n",
    "print(f\"   Errors: {len(errors_goe)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Validation - Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VALIDATION - After LLM Labeling\n",
      "================================================================================\n",
      "\n",
      "Null counts:\n",
      "text                   0\n",
      "emotion_label          0\n",
      "emotion_name           0\n",
      "source_dataset         0\n",
      "crisis_label           0\n",
      "event_type             0\n",
      "event_name             0\n",
      "informativeness    25587\n",
      "dtype: int64\n",
      "\n",
      "Emotion distribution:\n",
      "emotion_name\n",
      "neutral           12649\n",
      "caring             7445\n",
      "joy                5525\n",
      "anger              3671\n",
      "annoyance          3238\n",
      "admiration         2596\n",
      "disappointment     2505\n",
      "fear               2205\n",
      "gratitude          2040\n",
      "amusement          1934\n",
      "confusion          1595\n",
      "desire             1343\n",
      "excitement         1307\n",
      "surprise           1307\n",
      "sadness            1148\n",
      "curiosity          1079\n",
      "disgust            1044\n",
      "anxiety             132\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Crisis label distribution:\n",
      "crisis_label\n",
      "0.0    30875\n",
      "1.0    21888\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Event type distribution:\n",
      "event_type\n",
      "general_discussion    13581\n",
      "sports                 7709\n",
      "entertainment          6972\n",
      "flood                  3587\n",
      "wildfire               3587\n",
      "hurricane              3582\n",
      "earthquake             3577\n",
      "accident               3571\n",
      "politics               2571\n",
      "bombing                2000\n",
      "haze                   1000\n",
      "other_crisis            727\n",
      "pandemic                140\n",
      "shooting                 89\n",
      "not_related              37\n",
      "terrorism                32\n",
      "volcano                   1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"VALIDATION - After LLM Labeling\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nNull counts:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nEmotion distribution:\")\n",
    "print(df['emotion_name'].value_counts())\n",
    "\n",
    "print(f\"\\nCrisis label distribution:\")\n",
    "print(df['crisis_label'].value_counts())\n",
    "\n",
    "print(f\"\\nEvent type distribution:\")\n",
    "print(df['event_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Final Labeled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL LABELED DATASET SAVED\n",
      "================================================================================\n",
      "\n",
      "âœ… Saved to: master_training_data/master_training_data_v5_labelled.csv\n",
      "   File size: 9.11 MB\n",
      "   Total rows: 52,763\n",
      "\n",
      "All rows now have complete labels for BERT training!\n"
     ]
    }
   ],
   "source": [
    "# Save final labeled dataset\n",
    "OUTPUT_PATH = 'master_training_data/master_training_data_v5_labelled.csv'\n",
    "\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "file_size = Path(OUTPUT_PATH).stat().st_size / (1024**2)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL LABELED DATASET SAVED\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nâœ… Saved to: {OUTPUT_PATH}\")\n",
    "print(f\"   File size: {file_size:.2f} MB\")\n",
    "print(f\"   Total rows: {len(df):,}\")\n",
    "print(f\"\\nAll rows now have complete labels for BERT training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created sample file: master_training_data/master_training_sample_v5_labelled.csv\n",
      "   Rows: 10,000\n"
     ]
    }
   ],
   "source": [
    "# Create sample file\n",
    "SAMPLE_PATH = 'master_training_data/master_training_sample_v5_labelled.csv'\n",
    "df_sample = df.sample(n=min(10000, len(df)), random_state=42)\n",
    "df_sample.to_csv(SAMPLE_PATH, index=False)\n",
    "\n",
    "print(f\"âœ… Created sample file: {SAMPLE_PATH}\")\n",
    "print(f\"   Rows: {len(df_sample):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LLM LABELING COMPLETE - FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Dataset Statistics:\n",
      "   Total rows: 52,763\n",
      "   Rows with emotion labels: 52,763\n",
      "   Rows with crisis labels: 52,763\n",
      "\n",
      "ðŸ“ Files Created:\n",
      "   Main: master_training_data/master_training_data_v5_labelled.csv\n",
      "   Sample: master_training_data/master_training_sample_v5_labelled.csv\n",
      "\n",
      "âœ… Dataset is now ready for multi-task BERT training!\n",
      "   - All rows have emotion_label and emotion_name\n",
      "   - All rows have crisis_label\n",
      "   - All rows have event_type and informativeness\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LLM LABELING COMPLETE - FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Statistics:\")\n",
    "print(f\"   Total rows: {len(df):,}\")\n",
    "print(f\"   Rows with emotion labels: {df['emotion_label'].notna().sum():,}\")\n",
    "print(f\"   Rows with crisis labels: {df['crisis_label'].notna().sum():,}\")\n",
    "\n",
    "print(f\"\\nðŸ“ Files Created:\")\n",
    "print(f\"   Main: {OUTPUT_PATH}\")\n",
    "print(f\"   Sample: {SAMPLE_PATH}\")\n",
    "\n",
    "print(f\"\\nâœ… Dataset is now ready for multi-task BERT training!\")\n",
    "print(f\"   - All rows have emotion_label and emotion_name\")\n",
    "print(f\"   - All rows have crisis_label\")\n",
    "print(f\"   - All rows have event_type and informativeness\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
