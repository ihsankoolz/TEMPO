{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2824755c",
   "metadata": {},
   "source": [
    "# Phase 4: Create Master Training Dataset\n",
    "## Combine GoEmotions + Crisis + Non-Crisis Data\n",
    "\n",
    "This notebook:\n",
    "1. Loads GoEmotions with 13 emotions (has emotion labels)\n",
    "2. Loads crisis data with emotion columns (labels = NULL)\n",
    "3. Loads non-crisis data with emotion columns (labels = NULL)\n",
    "4. Standardizes all columns across datasets\n",
    "5. Combines into single master training file\n",
    "6. Validates and saves final dataset\n",
    "\n",
    "### Data Sources:\n",
    "- **GoEmotions**: 54K Reddit comments with labeled emotions (for BERT training)\n",
    "- **Crisis**: 66K crisis tweets (BERT will predict emotions)\n",
    "- **Non-Crisis**: 1.5M non-crisis tweets (BERT will predict emotions)\n",
    "- **Total**: ~1.6M rows for comprehensive emotion classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9085155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378adf6",
   "metadata": {},
   "source": [
    "## 1. Load All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60f45d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "\n",
      "1. GoEmotions (with 13 emotions)...\n",
      "   ‚úì Loaded 54,263 rows\n",
      "   Columns: ['text', 'emotion_label', 'emotion_name', 'id', 'labels']\n",
      "\n",
      "2. Crisis data (with emotion columns)...\n",
      "   ‚úì Loaded 66,748 rows\n",
      "   Columns: ['text', 'created_at', 'event_name', 'event_type', 'crisis_label', 'source_dataset', 'informativeness', 'emotion_label', 'emotion_name']\n",
      "\n",
      "3. Non-crisis data (with emotion columns)...\n",
      "   ‚úì Loaded 1,533,696 rows\n",
      "   Columns: ['text', 'created_at', 'event_name', 'event_type', 'crisis_label', 'source_dataset', 'emotion_label', 'emotion_name']\n",
      "\n",
      "================================================================================\n",
      "Total rows to combine: 1,654,707\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\\n\")\n",
    "\n",
    "# Load GoEmotions with 13 emotions\n",
    "print(\"1. GoEmotions (with 13 emotions)...\")\n",
    "df_goemotions = pd.read_csv('goemotion_data/goemotions_with_13_emotions.csv')\n",
    "print(f\"   ‚úì Loaded {len(df_goemotions):,} rows\")\n",
    "print(f\"   Columns: {df_goemotions.columns.tolist()}\")\n",
    "\n",
    "# Load crisis data with emotion columns\n",
    "print(\"\\n2. Crisis data (with emotion columns)...\")\n",
    "df_crisis = pd.read_csv('standardized_data/crisis_combined_with_emotions.csv')\n",
    "print(f\"   ‚úì Loaded {len(df_crisis):,} rows\")\n",
    "print(f\"   Columns: {df_crisis.columns.tolist()}\")\n",
    "\n",
    "# Load non-crisis data with emotion columns\n",
    "print(\"\\n3. Non-crisis data (with emotion columns)...\")\n",
    "df_non_crisis = pd.read_csv('standardized_data/non_crisis_combined_with_emotions.csv')\n",
    "print(f\"   ‚úì Loaded {len(df_non_crisis):,} rows\")\n",
    "print(f\"   Columns: {df_non_crisis.columns.tolist()}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Total rows to combine: {len(df_goemotions) + len(df_crisis) + len(df_non_crisis):,}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677bdfd9",
   "metadata": {},
   "source": [
    "## 2. Check Current Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b68ba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current column schemas:\n",
      "\n",
      "GoEmotions columns:\n",
      "  - text: str\n",
      "  - emotion_label: int64\n",
      "  - emotion_name: str\n",
      "  - id: str\n",
      "  - labels: str\n",
      "\n",
      "Crisis columns:\n",
      "  - text: str\n",
      "  - created_at: str\n",
      "  - event_name: str\n",
      "  - event_type: str\n",
      "  - crisis_label: int64\n",
      "  - source_dataset: str\n",
      "  - informativeness: str\n",
      "  - emotion_label: float64\n",
      "  - emotion_name: float64\n",
      "\n",
      "Non-crisis columns:\n",
      "  - text: str\n",
      "  - created_at: str\n",
      "  - event_name: str\n",
      "  - event_type: str\n",
      "  - crisis_label: int64\n",
      "  - source_dataset: str\n",
      "  - emotion_label: float64\n",
      "  - emotion_name: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Current column schemas:\\n\")\n",
    "\n",
    "print(\"GoEmotions columns:\")\n",
    "for col in df_goemotions.columns:\n",
    "    print(f\"  - {col}: {df_goemotions[col].dtype}\")\n",
    "\n",
    "print(\"\\nCrisis columns:\")\n",
    "for col in df_crisis.columns:\n",
    "    print(f\"  - {col}: {df_crisis[col].dtype}\")\n",
    "\n",
    "print(\"\\nNon-crisis columns:\")\n",
    "for col in df_non_crisis.columns:\n",
    "    print(f\"  - {col}: {df_non_crisis[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59d6cb2",
   "metadata": {},
   "source": [
    "## 3. Define Master Schema\n",
    "\n",
    "Create unified column structure for all datasets:\n",
    "- **text**: Tweet/comment text\n",
    "- **emotion_label**: Numeric emotion (1-13, NULL for unlabeled)\n",
    "- **emotion_name**: Text emotion name (NULL for unlabeled)\n",
    "- **source_dataset**: Origin of data (GoEmotions, HumAID, CrisisLex, etc.)\n",
    "- **crisis_label**: Binary (1=crisis, 0=non-crisis, NULL for GoEmotions)\n",
    "- **event_type**: General category (hurricane, sports, etc., NULL for GoEmotions)\n",
    "- **event_name**: Specific event (hurricane_harvey_2017, etc., NULL for GoEmotions)\n",
    "- **created_at**: Timestamp (NULL for GoEmotions)\n",
    "- **informativeness**: CrisisLex informativeness label (NULL for others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403345da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master schema columns:\n",
      "  1. text\n",
      "  2. emotion_label\n",
      "  3. emotion_name\n",
      "  4. source_dataset\n",
      "  5. crisis_label\n",
      "  6. event_type\n",
      "  7. event_name\n",
      "  8. created_at\n",
      "  9. informativeness\n"
     ]
    }
   ],
   "source": [
    "# Define master column set\n",
    "MASTER_COLUMNS = [\n",
    "    'text',\n",
    "    'emotion_label',\n",
    "    'emotion_name',\n",
    "    'source_dataset',\n",
    "    'crisis_label',\n",
    "    'event_type',\n",
    "    'event_name',\n",
    "    'created_at',\n",
    "    'informativeness'\n",
    "]\n",
    "\n",
    "print(\"Master schema columns:\")\n",
    "for i, col in enumerate(MASTER_COLUMNS, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec4a07",
   "metadata": {},
   "source": [
    "## 4. Standardize GoEmotions Data\n",
    "\n",
    "Add missing columns to GoEmotions dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "311e49b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing GoEmotions data...\n",
      "\n",
      "‚úì GoEmotions standardized: 54,263 rows\n",
      "  Columns: ['text', 'emotion_label', 'emotion_name', 'source_dataset', 'crisis_label', 'event_type', 'event_name', 'created_at', 'informativeness']\n",
      "\n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>emotion_name</th>\n",
       "      <th>source_dataset</th>\n",
       "      <th>crisis_label</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>informativeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to cook myself.</td>\n",
       "      <td>13</td>\n",
       "      <td>neutral</td>\n",
       "      <td>GoEmotions</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will think hes having a laugh screwing with people instead ...</td>\n",
       "      <td>13</td>\n",
       "      <td>neutral</td>\n",
       "      <td>GoEmotions</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>2</td>\n",
       "      <td>anger</td>\n",
       "      <td>GoEmotions</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0                                          My favourite food is anything I didn't have to cook myself.   \n",
       "1  Now if he does off himself, everyone will think hes having a laugh screwing with people instead ...   \n",
       "2                                                                       WHY THE FUCK IS BAYLESS ISOING   \n",
       "\n",
       "   emotion_label emotion_name source_dataset  crisis_label event_type  \\\n",
       "0             13      neutral     GoEmotions           NaN              \n",
       "1             13      neutral     GoEmotions           NaN              \n",
       "2              2        anger     GoEmotions           NaN              \n",
       "\n",
       "  event_name created_at informativeness  \n",
       "0                                        \n",
       "1                                        \n",
       "2                                        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Standardizing GoEmotions data...\\n\")\n",
    "\n",
    "# Create standardized GoEmotions dataframe\n",
    "df_goemotions_std = pd.DataFrame()\n",
    "\n",
    "# Keep existing columns\n",
    "df_goemotions_std['text'] = df_goemotions['text']\n",
    "df_goemotions_std['emotion_label'] = df_goemotions['emotion_label']\n",
    "df_goemotions_std['emotion_name'] = df_goemotions['emotion_name']\n",
    "\n",
    "# Add source\n",
    "df_goemotions_std['source_dataset'] = 'GoEmotions'\n",
    "\n",
    "# Add NULL columns (GoEmotions is not crisis-related)\n",
    "df_goemotions_std['crisis_label'] = np.nan\n",
    "df_goemotions_std['event_type'] = ''\n",
    "df_goemotions_std['event_name'] = ''\n",
    "df_goemotions_std['created_at'] = ''\n",
    "df_goemotions_std['informativeness'] = ''\n",
    "\n",
    "print(f\"‚úì GoEmotions standardized: {len(df_goemotions_std):,} rows\")\n",
    "print(f\"  Columns: {df_goemotions_std.columns.tolist()}\")\n",
    "print(f\"\\nSample:\")\n",
    "display(df_goemotions_std.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cfc574",
   "metadata": {},
   "source": [
    "## 5. Standardize Crisis Data\n",
    "\n",
    "Select and reorder crisis columns to match master schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0969d83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing crisis data...\n",
      "\n",
      "‚úì Crisis standardized: 66,748 rows\n",
      "  Columns: ['text', 'emotion_label', 'emotion_name', 'source_dataset', 'crisis_label', 'event_type', 'event_name', 'created_at', 'informativeness']\n",
      "\n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>emotion_name</th>\n",
       "      <th>source_dataset</th>\n",
       "      <th>crisis_label</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>informativeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@GreenABEnergy How can @AirworksCanada assist in the cleanup? #AlbertaStrong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>humaid</td>\n",
       "      <td>1</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>canada_wildfires_2016_dev</td>\n",
       "      <td>2016-05-19 18:16:11.727000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @katvondawn: Thoughts &amp;amp; prayers going to all those being affected by the wildfire in Cana...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>humaid</td>\n",
       "      <td>1</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>canada_wildfires_2016_dev</td>\n",
       "      <td>2016-05-09 03:58:37.448000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glacier Farm Media pledges $50K in support for Fort McMurray wildfire disaster relief.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>humaid</td>\n",
       "      <td>1</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>canada_wildfires_2016_dev</td>\n",
       "      <td>2016-05-12 12:41:05.044000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0                        .@GreenABEnergy How can @AirworksCanada assist in the cleanup? #AlbertaStrong   \n",
       "1  RT @katvondawn: Thoughts &amp; prayers going to all those being affected by the wildfire in Cana...   \n",
       "2               Glacier Farm Media pledges $50K in support for Fort McMurray wildfire disaster relief.   \n",
       "\n",
       "   emotion_label  emotion_name source_dataset  crisis_label event_type  \\\n",
       "0            NaN           NaN         humaid             1   wildfire   \n",
       "1            NaN           NaN         humaid             1   wildfire   \n",
       "2            NaN           NaN         humaid             1   wildfire   \n",
       "\n",
       "                  event_name                        created_at informativeness  \n",
       "0  canada_wildfires_2016_dev  2016-05-19 18:16:11.727000+00:00             NaN  \n",
       "1  canada_wildfires_2016_dev  2016-05-09 03:58:37.448000+00:00             NaN  \n",
       "2  canada_wildfires_2016_dev  2016-05-12 12:41:05.044000+00:00             NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Standardizing crisis data...\\n\")\n",
    "\n",
    "# Create standardized crisis dataframe\n",
    "df_crisis_std = pd.DataFrame()\n",
    "\n",
    "df_crisis_std['text'] = df_crisis['text']\n",
    "df_crisis_std['emotion_label'] = df_crisis['emotion_label']  # Will be NaN\n",
    "df_crisis_std['emotion_name'] = df_crisis['emotion_name']    # Will be empty\n",
    "df_crisis_std['source_dataset'] = df_crisis['source_dataset']\n",
    "df_crisis_std['crisis_label'] = df_crisis['crisis_label']\n",
    "df_crisis_std['event_type'] = df_crisis['event_type']\n",
    "df_crisis_std['event_name'] = df_crisis['event_name']\n",
    "df_crisis_std['created_at'] = df_crisis['created_at']\n",
    "df_crisis_std['informativeness'] = df_crisis['informativeness']\n",
    "\n",
    "print(f\"‚úì Crisis standardized: {len(df_crisis_std):,} rows\")\n",
    "print(f\"  Columns: {df_crisis_std.columns.tolist()}\")\n",
    "print(f\"\\nSample:\")\n",
    "display(df_crisis_std.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e702522d",
   "metadata": {},
   "source": [
    "## 6. Standardize Non-Crisis Data\n",
    "\n",
    "Select and reorder non-crisis columns to match master schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfd741cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing non-crisis data...\n",
      "\n",
      "‚úì Non-crisis standardized: 1,533,696 rows\n",
      "  Columns: ['text', 'emotion_label', 'emotion_name', 'source_dataset', 'crisis_label', 'event_type', 'event_name', 'created_at', 'informativeness']\n",
      "\n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>emotion_name</th>\n",
       "      <th>source_dataset</th>\n",
       "      <th>crisis_label</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>informativeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Coachella2015 tickets selling out in less than 40 minutes _√ô_¬¶_√ô___√ô___√ô√∑¬ù_√ô√é¬µ_√ô√é¬µ_√ô___√ô_¬¶ http...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coachella</td>\n",
       "      <td>0</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>coachella_2015</td>\n",
       "      <td>2015-01-07 15:02:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @sudsybuddy: WAIT THIS IS ABSOLUTE FIRE _√ô√ì¬¥_√ô√ì¬¥_√ô√ì¬¥ #Coachella2015 http://t.co/Ov2eCJtAvR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coachella</td>\n",
       "      <td>0</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>coachella_2015</td>\n",
       "      <td>2015-01-07 15:02:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Coachella2015 #VIP passes secured! See you there bitchesssss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coachella</td>\n",
       "      <td>0</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>coachella_2015</td>\n",
       "      <td>2015-01-07 15:01:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  #Coachella2015 tickets selling out in less than 40 minutes _√ô_¬¶_√ô___√ô___√ô√∑¬ù_√ô√é¬µ_√ô√é¬µ_√ô___√ô_¬¶ http...   \n",
       "1        RT @sudsybuddy: WAIT THIS IS ABSOLUTE FIRE _√ô√ì¬¥_√ô√ì¬¥_√ô√ì¬¥ #Coachella2015 http://t.co/Ov2eCJtAvR   \n",
       "2                                        #Coachella2015 #VIP passes secured! See you there bitchesssss   \n",
       "\n",
       "   emotion_label  emotion_name source_dataset  crisis_label     event_type  \\\n",
       "0            NaN           NaN      coachella             0  entertainment   \n",
       "1            NaN           NaN      coachella             0  entertainment   \n",
       "2            NaN           NaN      coachella             0  entertainment   \n",
       "\n",
       "       event_name           created_at informativeness  \n",
       "0  coachella_2015  2015-01-07 15:02:00                  \n",
       "1  coachella_2015  2015-01-07 15:02:00                  \n",
       "2  coachella_2015  2015-01-07 15:01:00                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Standardizing non-crisis data...\\n\")\n",
    "\n",
    "# Create standardized non-crisis dataframe\n",
    "df_non_crisis_std = pd.DataFrame()\n",
    "\n",
    "df_non_crisis_std['text'] = df_non_crisis['text']\n",
    "df_non_crisis_std['emotion_label'] = df_non_crisis['emotion_label']  # Will be NaN\n",
    "df_non_crisis_std['emotion_name'] = df_non_crisis['emotion_name']    # Will be empty\n",
    "df_non_crisis_std['source_dataset'] = df_non_crisis['source_dataset']\n",
    "df_non_crisis_std['crisis_label'] = df_non_crisis['crisis_label']\n",
    "df_non_crisis_std['event_type'] = df_non_crisis['event_type']\n",
    "df_non_crisis_std['event_name'] = df_non_crisis['event_name']\n",
    "df_non_crisis_std['created_at'] = df_non_crisis['created_at']\n",
    "\n",
    "# Non-crisis doesn't have informativeness\n",
    "df_non_crisis_std['informativeness'] = ''\n",
    "\n",
    "print(f\"‚úì Non-crisis standardized: {len(df_non_crisis_std):,} rows\")\n",
    "print(f\"  Columns: {df_non_crisis_std.columns.tolist()}\")\n",
    "print(f\"\\nSample:\")\n",
    "display(df_non_crisis_std.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3fcb7",
   "metadata": {},
   "source": [
    "## 7. Validate Schema Alignment\n",
    "\n",
    "Ensure all three datasets have identical column structure before combining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec744ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SCHEMA VALIDATION\n",
      "================================================================================\n",
      "\n",
      "GoEmotions columns: ['text', 'emotion_label', 'emotion_name', 'source_dataset', 'crisis_label', 'event_type', 'event_name', 'created_at', 'informativeness']\n",
      "Crisis columns:     ['text', 'emotion_label', 'emotion_name', 'source_dataset', 'crisis_label', 'event_type', 'event_name', 'created_at', 'informativeness']\n",
      "Non-crisis columns: ['text', 'emotion_label', 'emotion_name', 'source_dataset', 'crisis_label', 'event_type', 'event_name', 'created_at', 'informativeness']\n",
      "\n",
      "‚úÖ All datasets have matching column structure!\n",
      "\n",
      "‚úÖ Columns match master schema!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SCHEMA VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check column names\n",
    "goemotions_cols = df_goemotions_std.columns.tolist()\n",
    "crisis_cols = df_crisis_std.columns.tolist()\n",
    "non_crisis_cols = df_non_crisis_std.columns.tolist()\n",
    "\n",
    "print(f\"\\nGoEmotions columns: {goemotions_cols}\")\n",
    "print(f\"Crisis columns:     {crisis_cols}\")\n",
    "print(f\"Non-crisis columns: {non_crisis_cols}\")\n",
    "\n",
    "# Validate all match\n",
    "if goemotions_cols == crisis_cols == non_crisis_cols:\n",
    "    print(\"\\n‚úÖ All datasets have matching column structure!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Column mismatch detected!\")\n",
    "    print(f\"\\nDifferences:\")\n",
    "    if goemotions_cols != crisis_cols:\n",
    "        print(f\"  GoEmotions vs Crisis: {set(goemotions_cols) ^ set(crisis_cols)}\")\n",
    "    if crisis_cols != non_crisis_cols:\n",
    "        print(f\"  Crisis vs Non-crisis: {set(crisis_cols) ^ set(non_crisis_cols)}\")\n",
    "\n",
    "# Check if columns match master schema\n",
    "if goemotions_cols == MASTER_COLUMNS:\n",
    "    print(\"\\n‚úÖ Columns match master schema!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Column order differs from master schema\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add23f7",
   "metadata": {},
   "source": [
    "## 8. Combine All Datasets\n",
    "\n",
    "Concatenate all three standardized datasets into master training file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba252696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining datasets...\n",
      "\n",
      "‚úÖ Combined master dataset created!\n",
      "\n",
      "Total rows: 1,654,707\n",
      "\n",
      "Breakdown:\n",
      "  GoEmotions:  54,263 (3.3%)\n",
      "  Crisis:      66,748 (4.0%)\n",
      "  Non-crisis:  1,533,696 (92.7%)\n",
      "\n",
      "Columns: ['text', 'emotion_label', 'emotion_name', 'source_dataset', 'crisis_label', 'event_type', 'event_name', 'created_at', 'informativeness']\n",
      "\n",
      "Memory usage: 864.60 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Combining datasets...\\n\")\n",
    "\n",
    "# Concatenate all datasets\n",
    "df_master = pd.concat([\n",
    "    df_goemotions_std,\n",
    "    df_crisis_std,\n",
    "    df_non_crisis_std\n",
    "], ignore_index=True)\n",
    "\n",
    "print(f\"‚úÖ Combined master dataset created!\")\n",
    "print(f\"\\nTotal rows: {len(df_master):,}\")\n",
    "print(f\"\\nBreakdown:\")\n",
    "print(f\"  GoEmotions:  {len(df_goemotions_std):,} ({len(df_goemotions_std)/len(df_master)*100:.1f}%)\")\n",
    "print(f\"  Crisis:      {len(df_crisis_std):,} ({len(df_crisis_std)/len(df_master)*100:.1f}%)\")\n",
    "print(f\"  Non-crisis:  {len(df_non_crisis_std):,} ({len(df_non_crisis_std)/len(df_master)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nColumns: {df_master.columns.tolist()}\")\n",
    "print(f\"\\nMemory usage: {df_master.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d310a",
   "metadata": {},
   "source": [
    "## 9. Data Quality Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b43a23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA QUALITY VALIDATION\n",
      "================================================================================\n",
      "\n",
      "Null counts:\n",
      "text                   537\n",
      "emotion_label      1600444\n",
      "emotion_name       1600444\n",
      "source_dataset           0\n",
      "crisis_label         54263\n",
      "event_type               0\n",
      "event_name               0\n",
      "created_at               0\n",
      "informativeness      43816\n",
      "dtype: int64\n",
      "\n",
      "Text validation:\n",
      "  Null texts: 537\n",
      "  Empty texts: 0\n",
      "\n",
      "Emotion label status:\n",
      "  Labeled (GoEmotions):    54,263 (3.3%)\n",
      "  Unlabeled (Crisis+Non):  1,600,444 (96.7%)\n",
      "\n",
      "Crisis label distribution:\n",
      "  Crisis (1):      66,748\n",
      "  Non-crisis (0):  1,533,696\n",
      "  Unlabeled (GoE): 54,263\n",
      "\n",
      "Source dataset distribution:\n",
      "source_dataset\n",
      "game_of_thrones    760614\n",
      "worldcup_2018      458533\n",
      "tokyo_olympics     159432\n",
      "us_election         99948\n",
      "GoEmotions          54263\n",
      "fifa_worldcup       49493\n",
      "humaid              43409\n",
      "crisislex           23339\n",
      "coachella            3846\n",
      "music_concerts       1830\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DATA QUALITY VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check for nulls in critical columns\n",
    "print(f\"\\nNull counts:\")\n",
    "print(df_master.isnull().sum())\n",
    "\n",
    "# Check text column\n",
    "null_text = df_master['text'].isna().sum()\n",
    "empty_text = (df_master['text'] == '').sum()\n",
    "print(f\"\\nText validation:\")\n",
    "print(f\"  Null texts: {null_text}\")\n",
    "print(f\"  Empty texts: {empty_text}\")\n",
    "if null_text == 0 and empty_text == 0:\n",
    "    print(f\"  ‚úÖ All rows have text content\")\n",
    "\n",
    "# Check emotion labels\n",
    "labeled_rows = df_master['emotion_label'].notna().sum()\n",
    "unlabeled_rows = df_master['emotion_label'].isna().sum()\n",
    "print(f\"\\nEmotion label status:\")\n",
    "print(f\"  Labeled (GoEmotions):    {labeled_rows:,} ({labeled_rows/len(df_master)*100:.1f}%)\")\n",
    "print(f\"  Unlabeled (Crisis+Non):  {unlabeled_rows:,} ({unlabeled_rows/len(df_master)*100:.1f}%)\")\n",
    "\n",
    "# Check crisis labels\n",
    "crisis_rows = (df_master['crisis_label'] == 1).sum()\n",
    "non_crisis_rows = (df_master['crisis_label'] == 0).sum()\n",
    "unlabeled_crisis = df_master['crisis_label'].isna().sum()\n",
    "print(f\"\\nCrisis label distribution:\")\n",
    "print(f\"  Crisis (1):      {crisis_rows:,}\")\n",
    "print(f\"  Non-crisis (0):  {non_crisis_rows:,}\")\n",
    "print(f\"  Unlabeled (GoE): {unlabeled_crisis:,}\")\n",
    "\n",
    "# Check source distribution\n",
    "print(f\"\\nSource dataset distribution:\")\n",
    "print(df_master['source_dataset'].value_counts())\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3e5d6",
   "metadata": {},
   "source": [
    "## 10. Show Sample Data from Each Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e09420da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rows from each source:\n",
      "\n",
      "GoEmotions sample (with emotion labels):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>emotion_name</th>\n",
       "      <th>source_dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to cook myself.</td>\n",
       "      <td>13.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>GoEmotions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will think hes having a laugh screwing with people instead ...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>GoEmotions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>2.0</td>\n",
       "      <td>anger</td>\n",
       "      <td>GoEmotions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0                                          My favourite food is anything I didn't have to cook myself.   \n",
       "1  Now if he does off himself, everyone will think hes having a laugh screwing with people instead ...   \n",
       "2                                                                       WHY THE FUCK IS BAYLESS ISOING   \n",
       "\n",
       "   emotion_label emotion_name source_dataset  \n",
       "0           13.0      neutral     GoEmotions  \n",
       "1           13.0      neutral     GoEmotions  \n",
       "2            2.0        anger     GoEmotions  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crisis sample (emotion labels = NULL):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>emotion_name</th>\n",
       "      <th>event_name</th>\n",
       "      <th>crisis_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54263</th>\n",
       "      <td>.@GreenABEnergy How can @AirworksCanada assist in the cleanup? #AlbertaStrong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>canada_wildfires_2016_dev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54264</th>\n",
       "      <td>RT @katvondawn: Thoughts &amp;amp; prayers going to all those being affected by the wildfire in Cana...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>canada_wildfires_2016_dev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54265</th>\n",
       "      <td>Glacier Farm Media pledges $50K in support for Fort McMurray wildfire disaster relief.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>canada_wildfires_2016_dev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      text  \\\n",
       "54263                        .@GreenABEnergy How can @AirworksCanada assist in the cleanup? #AlbertaStrong   \n",
       "54264  RT @katvondawn: Thoughts &amp; prayers going to all those being affected by the wildfire in Cana...   \n",
       "54265               Glacier Farm Media pledges $50K in support for Fort McMurray wildfire disaster relief.   \n",
       "\n",
       "       emotion_label emotion_name                 event_name  crisis_label  \n",
       "54263            NaN          NaN  canada_wildfires_2016_dev           1.0  \n",
       "54264            NaN          NaN  canada_wildfires_2016_dev           1.0  \n",
       "54265            NaN          NaN  canada_wildfires_2016_dev           1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-crisis sample (emotion labels = NULL):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>emotion_name</th>\n",
       "      <th>event_name</th>\n",
       "      <th>crisis_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121011</th>\n",
       "      <td>#Coachella2015 tickets selling out in less than 40 minutes _√ô_¬¶_√ô___√ô___√ô√∑¬ù_√ô√é¬µ_√ô√é¬µ_√ô___√ô_¬¶ http...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coachella_2015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121012</th>\n",
       "      <td>RT @sudsybuddy: WAIT THIS IS ABSOLUTE FIRE _√ô√ì¬¥_√ô√ì¬¥_√ô√ì¬¥ #Coachella2015 http://t.co/Ov2eCJtAvR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coachella_2015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121013</th>\n",
       "      <td>#Coachella2015 #VIP passes secured! See you there bitchesssss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coachella_2015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       text  \\\n",
       "121011  #Coachella2015 tickets selling out in less than 40 minutes _√ô_¬¶_√ô___√ô___√ô√∑¬ù_√ô√é¬µ_√ô√é¬µ_√ô___√ô_¬¶ http...   \n",
       "121012        RT @sudsybuddy: WAIT THIS IS ABSOLUTE FIRE _√ô√ì¬¥_√ô√ì¬¥_√ô√ì¬¥ #Coachella2015 http://t.co/Ov2eCJtAvR   \n",
       "121013                                        #Coachella2015 #VIP passes secured! See you there bitchesssss   \n",
       "\n",
       "        emotion_label emotion_name      event_name  crisis_label  \n",
       "121011            NaN          NaN  coachella_2015           0.0  \n",
       "121012            NaN          NaN  coachella_2015           0.0  \n",
       "121013            NaN          NaN  coachella_2015           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Sample rows from each source:\\n\")\n",
    "\n",
    "print(\"GoEmotions sample (with emotion labels):\")\n",
    "display(df_master[df_master['source_dataset'] == 'GoEmotions'][['text', 'emotion_label', 'emotion_name', 'source_dataset']].head(3))\n",
    "\n",
    "print(\"\\nCrisis sample (emotion labels = NULL):\")\n",
    "crisis_sample = df_master[df_master['crisis_label'] == 1][['text', 'emotion_label', 'emotion_name', 'event_name', 'crisis_label']].head(3)\n",
    "display(crisis_sample)\n",
    "\n",
    "print(\"\\nNon-crisis sample (emotion labels = NULL):\")\n",
    "non_crisis_sample = df_master[df_master['crisis_label'] == 0][['text', 'emotion_label', 'emotion_name', 'event_name', 'crisis_label']].head(3)\n",
    "display(non_crisis_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e489f01",
   "metadata": {},
   "source": [
    "## 11. Save Master Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0010022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving master training dataset to master_training_data/master_training_data_v2.csv...\n",
      "\n",
      "================================================================================\n",
      "MASTER DATASET SAVED\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Saved to: master_training_data/master_training_data_v2.csv\n",
      "\n",
      "File size: 289.75 MB\n",
      "Total rows: 1,654,707\n",
      "Total columns: 9\n",
      "\n",
      "Columns: ['text', 'emotion_label', 'emotion_name', 'source_dataset', 'crisis_label', 'event_type', 'event_name', 'created_at', 'informativeness']\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save to master_training_data folder\n",
    "output_path = 'master_training_data/master_training_data_v2.csv'\n",
    "\n",
    "print(f\"Saving master training dataset to {output_path}...\\n\")\n",
    "df_master.to_csv(output_path, index=False)\n",
    "\n",
    "file_size = Path(output_path).stat().st_size / (1024**2)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MASTER DATASET SAVED\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n‚úÖ Saved to: {output_path}\")\n",
    "print(f\"\\nFile size: {file_size:.2f} MB\")\n",
    "print(f\"Total rows: {len(df_master):,}\")\n",
    "print(f\"Total columns: {len(df_master.columns)}\")\n",
    "print(f\"\\nColumns: {df_master.columns.tolist()}\")\n",
    "print(f\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689328d9",
   "metadata": {},
   "source": [
    "## 12. Create Smaller Sample File for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce99657e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created sample file: master_training_data/master_training_sample_10k.csv\n",
      "   Rows: 10,000\n",
      "   Size: 1.75 MB\n"
     ]
    }
   ],
   "source": [
    "# Create 10K sample for quick testing\n",
    "sample_size = 10000\n",
    "df_sample = df_master.sample(n=sample_size, random_state=42)\n",
    "\n",
    "sample_path = 'master_training_data/master_training_sample_10k.csv'\n",
    "df_sample.to_csv(sample_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Created sample file: {sample_path}\")\n",
    "print(f\"   Rows: {len(df_sample):,}\")\n",
    "print(f\"   Size: {Path(sample_path).stat().st_size / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5ee71",
   "metadata": {},
   "source": [
    "## 13. Final Summary & Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67521c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "üìä Dataset Composition:\n",
      "   Total rows:          1,654,707\n",
      "   GoEmotions:          54,263 (with emotion labels)\n",
      "   Crisis events:       66,748 (emotion labels = NULL)\n",
      "   Non-crisis events:   1,533,696 (emotion labels = NULL)\n",
      "\n",
      "üìÅ Files Created:\n",
      "   Main:   master_training_data/master_training_data_v2.csv (289.75 MB)\n",
      "   Sample: master_training_data/master_training_sample_10k.csv\n",
      "\n",
      "üè∑Ô∏è Emotion Labels:\n",
      "   Labeled rows:    54,263 (GoEmotions - for training)\n",
      "   Unlabeled rows:  1,600,444 (Crisis + Non-crisis - for prediction)\n",
      "\n",
      "üîß Schema:\n",
      "   Columns: 9\n",
      "      1. text\n",
      "      2. emotion_label\n",
      "      3. emotion_name\n",
      "      4. source_dataset\n",
      "      5. crisis_label\n",
      "      6. event_type\n",
      "      7. event_name\n",
      "      8. created_at\n",
      "      9. informativeness\n",
      "\n",
      "üìã Next Steps:\n",
      "   1. Train BERT on GoEmotions data (54K labeled rows)\n",
      "   2. Use trained BERT to predict emotions for Crisis/Non-crisis data\n",
      "   3. Fill emotion_label and emotion_name for unlabeled rows\n",
      "   4. Analyze fear/anxiety patterns in crisis vs non-crisis events\n",
      "   5. Build temporal analysis for crisis detection\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PHASE 4 COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìä Dataset Composition:\")\n",
    "print(f\"   Total rows:          {len(df_master):,}\")\n",
    "print(f\"   GoEmotions:          {len(df_goemotions_std):,} (with emotion labels)\")\n",
    "print(f\"   Crisis events:       {len(df_crisis_std):,} (emotion labels = NULL)\")\n",
    "print(f\"   Non-crisis events:   {len(df_non_crisis_std):,} (emotion labels = NULL)\")\n",
    "\n",
    "print(f\"\\nüìÅ Files Created:\")\n",
    "print(f\"   Main:   master_training_data/master_training_data_v2.csv ({file_size:.2f} MB)\")\n",
    "print(f\"   Sample: master_training_data/master_training_sample_10k.csv\")\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è Emotion Labels:\")\n",
    "print(f\"   Labeled rows:    {labeled_rows:,} (GoEmotions - for training)\")\n",
    "print(f\"   Unlabeled rows:  {unlabeled_rows:,} (Crisis + Non-crisis - for prediction)\")\n",
    "\n",
    "print(f\"\\nüîß Schema:\")\n",
    "print(f\"   Columns: {len(df_master.columns)}\")\n",
    "for i, col in enumerate(df_master.columns, 1):\n",
    "    print(f\"      {i}. {col}\")\n",
    "\n",
    "print(f\"\\nüìã Next Steps:\")\n",
    "print(f\"   1. Train BERT on GoEmotions data (54K labeled rows)\")\n",
    "print(f\"   2. Use trained BERT to predict emotions for Crisis/Non-crisis data\")\n",
    "print(f\"   3. Fill emotion_label and emotion_name for unlabeled rows\")\n",
    "print(f\"   4. Analyze fear/anxiety patterns in crisis vs non-crisis events\")\n",
    "print(f\"   5. Build temporal analysis for crisis detection\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ PHASE 4 COMPLETE!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
