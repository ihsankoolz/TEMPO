{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 6: Multi-Task BERT Training\n",
    "## Fine-tune bert-base-uncased for Emotion + Crisis + Informativeness Classification\n",
    "\n",
    "This notebook trains a **multi-task BERT model** with three classification heads:\n",
    "- **Emotion** (13 classes): fear, anger, sadness, anxiety, confusion, surprise, disgust, caring, joy, excitement, gratitude, disappointment, neutral\n",
    "- **Crisis** (2 classes): crisis vs. non-crisis\n",
    "- **Informativeness** (3 classes): related_informative, related_not_informative, not_related\n",
    "\n",
    "### Architecture\n",
    "```\n",
    "Input text -> BERT Tokenizer (max_length=128)\n",
    "           -> BERT base encoder (shared, 768-dim)\n",
    "           -> [CLS] token embedding\n",
    "           |-> Dropout(0.3) -> Linear(768, 13) -> Emotion logits\n",
    "           |-> Dropout(0.3) -> Linear(768,  2) -> Crisis logits\n",
    "           |-> Dropout(0.3) -> Linear(768,  3) -> Informativeness logits\n",
    "```\n",
    "\n",
    "### Training Config\n",
    "- Learning rate: 2e-5, Batch size: 16, Epochs: 3, Max length: 128 tokens\n",
    "- Optimizer: AdamW (weight_decay=0.01), Scheduler: Linear warmup (10%)\n",
    "- Loss: CrossEntropyLoss per task (weighted for emotion), summed equally\n",
    "\n",
    "### Prerequisites\n",
    "- Run notebook 06 first to create the labelled datasets\n",
    "- Starting with the 10K sample for development, switch to full 52.8K for final training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab: Uncomment the following lines to install required packages\n",
    "# !pip install transformers accelerate -q\n",
    "# !pip install scikit-learn tqdm matplotlib seaborn -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"\\u2705 Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Device Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab: Uncomment to mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Device setup\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    # Corrected: Changed 'total_mem' to 'total_memory'\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"✅ GPU available: {gpu_name} ({gpu_mem:.1f} GB)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"☢️  No GPU found - using CPU (training will be slow)\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - Edit this cell to change settings\n",
    "# ============================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # --- DATA ---\n",
    "    # Switch between 10K sample and full dataset by changing this path:\n",
    "    # 'DATA_PATH': 'master_training_data/master_training_sample_v5_labelled (3).csv',\n",
    "    # 'DATA_PATH': 'master_training_data/master_training_data_v5_labelled.csv',  # Full 52.8K\n",
    "    \n",
    "    # For Colab with Google Drive:\n",
    "    'DATA_PATH': '/content/drive/MyDrive/Tempo/master_training_sample_v5_labelled (3).csv',\n",
    "    \n",
    "    # --- MODEL ---\n",
    "    'MODEL_NAME': 'bert-base-uncased',\n",
    "    'MAX_LENGTH': 128,\n",
    "    \n",
    "    # --- TRAINING ---\n",
    "    'BATCH_SIZE': 16,\n",
    "    'EPOCHS': 3,\n",
    "    'LEARNING_RATE': 2e-5,\n",
    "    'WEIGHT_DECAY': 0.01,\n",
    "    'WARMUP_RATIO': 0.1,\n",
    "    'DROPOUT': 0.3,\n",
    "    'GRADIENT_ACCUMULATION_STEPS': 1,  # Increase to 2 or 4 if GPU runs out of memory\n",
    "    \n",
    "    # --- TASKS ---\n",
    "    'NUM_EMOTION_CLASSES': 13,\n",
    "    'NUM_CRISIS_CLASSES': 2,\n",
    "    'NUM_INFO_CLASSES': 3,\n",
    "    \n",
    "    # --- SAVING ---\n",
    "    'SAVE_DIR': '/content/drive/MyDrive/Tempo/saved_models/multitask_bert',\n",
    "    'RANDOM_SEED': 42,\n",
    "}\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(CONFIG['RANDOM_SEED'])\n",
    "np.random.seed(CONFIG['RANDOM_SEED'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(CONFIG['RANDOM_SEED'])\n",
    "\n",
    "print(\"\\u2705 Configuration set:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CONFIG['DATA_PATH'])\n",
    "print(f\"\\u2705 Loaded {len(df):,} rows from {CONFIG['DATA_PATH']}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nDtypes:\\n{df.dtypes}\")\n",
    "print(f\"\\nNull counts:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Emotion Label Merge (18 -> 13)\n",
    "\n",
    "The dataset contains **18 unique emotion names** from two different labeling schemes (GoEmotions original vs Gemini LLM). The `emotion_label` column is **inconsistent** (same number maps to different emotions depending on the source), so we use `emotion_name` as the source of truth and merge 5 emotions:\n",
    "\n",
    "| Merge From | Merge To | Rationale |\n",
    "|-----------|----------|----------|\n",
    "| admiration | gratitude | Both express positive regard/appreciation |\n",
    "| amusement | joy | Both express positive/happy feelings |\n",
    "| annoyance | anger | Annoyance is a milder form of anger |\n",
    "| curiosity | confusion | Both involve uncertainty/seeking understanding |\n",
    "| desire | excitement | Both involve positive anticipation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-merge distribution\n",
    "print(\"PRE-MERGE emotion distribution (18 unique):\")\n",
    "print(df['emotion_name'].value_counts())\n",
    "print(f\"\\nUnique emotion names: {df['emotion_name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the merge mapping\n",
    "EMOTION_MERGE = {\n",
    "    'admiration': 'gratitude',\n",
    "    'amusement': 'joy',\n",
    "    'annoyance': 'anger',\n",
    "    'curiosity': 'confusion',\n",
    "    'desire': 'excitement',\n",
    "}\n",
    "\n",
    "# Apply merge\n",
    "df['emotion_name'] = df['emotion_name'].replace(EMOTION_MERGE)\n",
    "\n",
    "# Verify exactly 13 unique emotions\n",
    "assert df['emotion_name'].nunique() == 13, f\"Expected 13, got {df['emotion_name'].nunique()}\"\n",
    "\n",
    "# Define the canonical 13 emotions (ordered for label indices 0-12)\n",
    "EMOTION_NAMES_13 = [\n",
    "    'fear', 'anger', 'sadness', 'anxiety', 'confusion',\n",
    "    'surprise', 'disgust', 'caring', 'joy', 'excitement',\n",
    "    'gratitude', 'disappointment', 'neutral'\n",
    "]\n",
    "\n",
    "# Create 0-indexed mapping for PyTorch CrossEntropyLoss\n",
    "EMOTION_TO_IDX = {name: idx for idx, name in enumerate(EMOTION_NAMES_13)}\n",
    "IDX_TO_EMOTION = {idx: name for name, idx in EMOTION_TO_IDX.items()}\n",
    "\n",
    "# Apply new labels\n",
    "df['emotion_idx'] = df['emotion_name'].map(EMOTION_TO_IDX)\n",
    "\n",
    "# Validate no NaNs\n",
    "assert df['emotion_idx'].isna().sum() == 0, \"Unmapped emotion names found!\"\n",
    "\n",
    "# Drop the old unreliable emotion_label column\n",
    "df.drop(columns=['emotion_label'], inplace=True)\n",
    "\n",
    "print(\"\\u2705 POST-MERGE emotion distribution (13 classes, 0-indexed):\")\n",
    "for name, idx in EMOTION_TO_IDX.items():\n",
    "    count = (df['emotion_idx'] == idx).sum()\n",
    "    print(f\"  {idx:2d}: {name:<16} ({count:,} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encode Crisis & Informativeness Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crisis: ensure integer type (may be float in full dataset)\n",
    "df['crisis_label'] = df['crisis_label'].astype(int)\n",
    "\n",
    "# Informativeness: string -> 0-indexed integer\n",
    "INFO_NAMES = ['related_informative', 'related_not_informative', 'not_related']\n",
    "INFO_TO_IDX = {name: idx for idx, name in enumerate(INFO_NAMES)}\n",
    "IDX_TO_INFO = {idx: name for name, idx in INFO_TO_IDX.items()}\n",
    "\n",
    "df['info_idx'] = df['informativeness'].map(INFO_TO_IDX)\n",
    "assert df['info_idx'].isna().sum() == 0, \"Unmapped informativeness values found!\"\n",
    "\n",
    "print(\"\\u2705 Crisis label distribution:\")\n",
    "print(df['crisis_label'].value_counts())\n",
    "\n",
    "print(f\"\\n\\u2705 Informativeness distribution (0-indexed):\")\n",
    "for name, idx in INFO_TO_IDX.items():\n",
    "    count = (df['info_idx'] == idx).sum()\n",
    "    print(f\"  {idx}: {name:<28} ({count:,} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compute Class Weights (Imbalanced Emotions)\n",
    "\n",
    "Emotion classes are highly imbalanced (e.g., anxiety: ~132 vs neutral: ~12,649 in the full dataset). We use inverse-frequency class weights so rare emotions contribute equally to the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute balanced class weights for emotion\n",
    "emotion_labels_array = df['emotion_idx'].values\n",
    "emotion_class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(CONFIG['NUM_EMOTION_CLASSES']),\n",
    "    y=emotion_labels_array\n",
    ")\n",
    "emotion_class_weights = torch.tensor(emotion_class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"\\u2705 Emotion class weights (balanced):\")\n",
    "for idx in range(CONFIG['NUM_EMOTION_CLASSES']):\n",
    "    name = IDX_TO_EMOTION[idx]\n",
    "    weight = emotion_class_weights[idx].item()\n",
    "    count = (df['emotion_idx'] == idx).sum()\n",
    "    print(f\"  {idx:2d} {name:<16}: weight={weight:.4f}  (n={count:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train/Test Split (80/20, Stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=CONFIG['RANDOM_SEED'],\n",
    "    stratify=df['emotion_idx']\n",
    ")\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\u2705 Train: {len(train_df):,} rows\")\n",
    "print(f\"\\u2705 Val:   {len(val_df):,} rows\")\n",
    "\n",
    "# Verify all classes present in both splits\n",
    "train_emotions = set(train_df['emotion_idx'].unique())\n",
    "val_emotions = set(val_df['emotion_idx'].unique())\n",
    "assert train_emotions == set(range(13)), f\"Missing train emotions: {set(range(13)) - train_emotions}\"\n",
    "assert val_emotions == set(range(13)), f\"Missing val emotions: {set(range(13)) - val_emotions}\"\n",
    "print(f\"\\n\\u2705 All 13 emotion classes present in both splits\")\n",
    "\n",
    "print(f\"\\nTrain crisis: {dict(train_df['crisis_label'].value_counts())}\")\n",
    "print(f\"Val crisis:   {dict(val_df['crisis_label'].value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for multi-task BERT training.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, tokenizer, max_length):\n",
    "        self.texts = dataframe['text'].tolist()\n",
    "        self.emotion_labels = dataframe['emotion_idx'].tolist()\n",
    "        self.crisis_labels = dataframe['crisis_label'].tolist()\n",
    "        self.info_labels = dataframe['info_idx'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'emotion_label': torch.tensor(self.emotion_labels[idx], dtype=torch.long),\n",
    "            'crisis_label': torch.tensor(self.crisis_labels[idx], dtype=torch.long),\n",
    "            'info_label': torch.tensor(self.info_labels[idx], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "print(\"\\u2705 MultiTaskDataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(CONFIG['MODEL_NAME'])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MultiTaskDataset(train_df, tokenizer, CONFIG['MAX_LENGTH'])\n",
    "val_dataset = MultiTaskDataset(val_df, tokenizer, CONFIG['MAX_LENGTH'])\n",
    "\n",
    "# Create dataloaders (num_workers=0 for Windows/Colab compatibility)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\u2705 Train: {len(train_dataset):,} samples, {len(train_loader):,} batches\")\n",
    "print(f\"\\u2705 Val:   {len(val_dataset):,} samples, {len(val_loader):,} batches\")\n",
    "\n",
    "# Sanity check: inspect one batch\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"\\nSample batch shapes:\")\n",
    "for key, val in batch.items():\n",
    "    print(f\"  {key}: {val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Architecture\n",
    "\n",
    "Shared BERT encoder with three independent classification heads:\n",
    "\n",
    "```\n",
    "[CLS] embedding (768-dim)\n",
    "   |\n",
    "   |---> Dropout(0.3) -> Linear(768, 13) -> Emotion logits\n",
    "   |---> Dropout(0.3) -> Linear(768,  2) -> Crisis logits\n",
    "   |---> Dropout(0.3) -> Linear(768,  3) -> Informativeness logits\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskBERT(nn.Module):\n",
    "    def __init__(self, model_name, num_emotions, num_crisis, num_info, dropout):\n",
    "        super(MultiTaskBERT, self).__init__()\n",
    "        \n",
    "        # Shared BERT encoder\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        hidden_size = self.bert.config.hidden_size  # 768\n",
    "        \n",
    "        # Task-specific classification heads\n",
    "        self.emotion_head = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, num_emotions)\n",
    "        )\n",
    "        \n",
    "        self.crisis_head = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, num_crisis)\n",
    "        )\n",
    "        \n",
    "        self.info_head = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, num_info)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Shared encoder\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # [CLS] token embedding\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # (batch_size, 768)\n",
    "        \n",
    "        # Task-specific logits\n",
    "        return {\n",
    "            'emotion': self.emotion_head(cls_output),   # (batch_size, 13)\n",
    "            'crisis': self.crisis_head(cls_output),     # (batch_size, 2)\n",
    "            'info': self.info_head(cls_output),         # (batch_size, 3)\n",
    "        }\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "model = MultiTaskBERT(\n",
    "    model_name=CONFIG['MODEL_NAME'],\n",
    "    num_emotions=CONFIG['NUM_EMOTION_CLASSES'],\n",
    "    num_crisis=CONFIG['NUM_CRISIS_CLASSES'],\n",
    "    num_info=CONFIG['NUM_INFO_CLASSES'],\n",
    "    dropout=CONFIG['DROPOUT']\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\u2705 Model loaded on {device}\")\n",
    "print(f\"   Total parameters:     {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Loss Functions, Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "emotion_criterion = nn.CrossEntropyLoss(weight=emotion_class_weights)\n",
    "crisis_criterion = nn.CrossEntropyLoss()\n",
    "info_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['LEARNING_RATE'],\n",
    "    weight_decay=CONFIG['WEIGHT_DECAY']\n",
    ")\n",
    "\n",
    "# Scheduler with linear warmup\n",
    "total_steps = (len(train_loader) // CONFIG['GRADIENT_ACCUMULATION_STEPS']) * CONFIG['EPOCHS']\n",
    "warmup_steps = int(total_steps * CONFIG['WARMUP_RATIO'])\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"\\u2705 Training setup:\")\n",
    "print(f\"   Total training steps: {total_steps:,}\")\n",
    "print(f\"   Warmup steps: {warmup_steps:,}\")\n",
    "print(f\"   Effective batch size: {CONFIG['BATCH_SIZE'] * CONFIG['GRADIENT_ACCUMULATION_STEPS']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, scheduler,\n",
    "                    emotion_criterion, crisis_criterion, info_criterion,\n",
    "                    device, accumulation_steps=1):\n",
    "    \"\"\"Train for one epoch. Returns dict of metrics.\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    task_losses = {'emotion': 0, 'crisis': 0, 'info': 0}\n",
    "    task_correct = {'emotion': 0, 'crisis': 0, 'info': 0}\n",
    "    total_samples = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
    "    for step, batch in pbar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        emotion_labels = batch['emotion_label'].to(device)\n",
    "        crisis_labels = batch['crisis_label'].to(device)\n",
    "        info_labels = batch['info_label'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        # Compute losses for each task\n",
    "        e_loss = emotion_criterion(logits['emotion'], emotion_labels)\n",
    "        c_loss = crisis_criterion(logits['crisis'], crisis_labels)\n",
    "        i_loss = info_criterion(logits['info'], info_labels)\n",
    "        \n",
    "        # Total loss (equal weighting)\n",
    "        loss = e_loss + c_loss + i_loss\n",
    "        \n",
    "        # Scale loss for gradient accumulation\n",
    "        scaled_loss = loss / accumulation_steps\n",
    "        scaled_loss.backward()\n",
    "        \n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Track metrics\n",
    "        batch_size = input_ids.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        task_losses['emotion'] += e_loss.item() * batch_size\n",
    "        task_losses['crisis'] += c_loss.item() * batch_size\n",
    "        task_losses['info'] += i_loss.item() * batch_size\n",
    "        \n",
    "        task_correct['emotion'] += (logits['emotion'].argmax(dim=1) == emotion_labels).sum().item()\n",
    "        task_correct['crisis'] += (logits['crisis'].argmax(dim=1) == crisis_labels).sum().item()\n",
    "        task_correct['info'] += (logits['info'].argmax(dim=1) == info_labels).sum().item()\n",
    "        total_samples += batch_size\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f\"{total_loss/total_samples:.4f}\",\n",
    "            'e_acc': f\"{task_correct['emotion']/total_samples:.3f}\",\n",
    "            'c_acc': f\"{task_correct['crisis']/total_samples:.3f}\",\n",
    "        })\n",
    "    \n",
    "    # Handle remaining gradients if steps not divisible by accumulation_steps\n",
    "    if (step + 1) % accumulation_steps != 0:\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / total_samples,\n",
    "        'emotion_loss': task_losses['emotion'] / total_samples,\n",
    "        'crisis_loss': task_losses['crisis'] / total_samples,\n",
    "        'info_loss': task_losses['info'] / total_samples,\n",
    "        'emotion_acc': task_correct['emotion'] / total_samples,\n",
    "        'crisis_acc': task_correct['crisis'] / total_samples,\n",
    "        'info_acc': task_correct['info'] / total_samples,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate(model, loader, emotion_criterion, crisis_criterion, info_criterion, device):\n",
    "    \"\"\"Evaluate on validation set. Returns dict of metrics + predictions.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    task_losses = {'emotion': 0, 'crisis': 0, 'info': 0}\n",
    "    task_correct = {'emotion': 0, 'crisis': 0, 'info': 0}\n",
    "    total_samples = 0\n",
    "    \n",
    "    all_preds = {'emotion': [], 'crisis': [], 'info': []}\n",
    "    all_labels = {'emotion': [], 'crisis': [], 'info': []}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            emotion_labels = batch['emotion_label'].to(device)\n",
    "            crisis_labels = batch['crisis_label'].to(device)\n",
    "            info_labels = batch['info_label'].to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            e_loss = emotion_criterion(logits['emotion'], emotion_labels)\n",
    "            c_loss = crisis_criterion(logits['crisis'], crisis_labels)\n",
    "            i_loss = info_criterion(logits['info'], info_labels)\n",
    "            loss = e_loss + c_loss + i_loss\n",
    "            \n",
    "            batch_size = input_ids.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            task_losses['emotion'] += e_loss.item() * batch_size\n",
    "            task_losses['crisis'] += c_loss.item() * batch_size\n",
    "            task_losses['info'] += i_loss.item() * batch_size\n",
    "            \n",
    "            e_preds = logits['emotion'].argmax(dim=1)\n",
    "            c_preds = logits['crisis'].argmax(dim=1)\n",
    "            i_preds = logits['info'].argmax(dim=1)\n",
    "            \n",
    "            task_correct['emotion'] += (e_preds == emotion_labels).sum().item()\n",
    "            task_correct['crisis'] += (c_preds == crisis_labels).sum().item()\n",
    "            task_correct['info'] += (i_preds == info_labels).sum().item()\n",
    "            total_samples += batch_size\n",
    "            \n",
    "            all_preds['emotion'].extend(e_preds.cpu().numpy())\n",
    "            all_preds['crisis'].extend(c_preds.cpu().numpy())\n",
    "            all_preds['info'].extend(i_preds.cpu().numpy())\n",
    "            all_labels['emotion'].extend(emotion_labels.cpu().numpy())\n",
    "            all_labels['crisis'].extend(crisis_labels.cpu().numpy())\n",
    "            all_labels['info'].extend(info_labels.cpu().numpy())\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / total_samples,\n",
    "        'emotion_loss': task_losses['emotion'] / total_samples,\n",
    "        'crisis_loss': task_losses['crisis'] / total_samples,\n",
    "        'info_loss': task_losses['info'] / total_samples,\n",
    "        'emotion_acc': task_correct['emotion'] / total_samples,\n",
    "        'crisis_acc': task_correct['crisis'] / total_samples,\n",
    "        'info_acc': task_correct['info'] / total_samples,\n",
    "        'all_preds': all_preds,\n",
    "        'all_labels': all_labels,\n",
    "    }\n",
    "\n",
    "print(\"\\u2705 Training and evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create save directory\n",
    "os.makedirs(CONFIG['SAVE_DIR'], exist_ok=True)\n",
    "\n",
    "# Training history for plotting\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_emotion_acc': [], 'val_emotion_acc': [],\n",
    "    'train_crisis_acc': [], 'val_crisis_acc': [],\n",
    "    'train_info_acc': [], 'val_info_acc': [],\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = -1\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(CONFIG['EPOCHS']):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Epoch {epoch+1}/{CONFIG['EPOCHS']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Train\n",
    "    train_metrics = train_one_epoch(\n",
    "        model, train_loader, optimizer, scheduler,\n",
    "        emotion_criterion, crisis_criterion, info_criterion,\n",
    "        device, CONFIG['GRADIENT_ACCUMULATION_STEPS']\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_metrics = evaluate(\n",
    "        model, val_loader,\n",
    "        emotion_criterion, crisis_criterion, info_criterion,\n",
    "        device\n",
    "    )\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_metrics['loss'])\n",
    "    history['val_loss'].append(val_metrics['loss'])\n",
    "    history['train_emotion_acc'].append(train_metrics['emotion_acc'])\n",
    "    history['val_emotion_acc'].append(val_metrics['emotion_acc'])\n",
    "    history['train_crisis_acc'].append(train_metrics['crisis_acc'])\n",
    "    history['val_crisis_acc'].append(val_metrics['crisis_acc'])\n",
    "    history['train_info_acc'].append(train_metrics['info_acc'])\n",
    "    history['val_info_acc'].append(val_metrics['info_acc'])\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\n--- Epoch {epoch+1} Summary ---\")\n",
    "    print(f\"{'Metric':<25} {'Train':>10} {'Val':>10}\")\n",
    "    print(f\"{'-'*45}\")\n",
    "    print(f\"{'Total Loss':<25} {train_metrics['loss']:>10.4f} {val_metrics['loss']:>10.4f}\")\n",
    "    print(f\"{'Emotion Loss':<25} {train_metrics['emotion_loss']:>10.4f} {val_metrics['emotion_loss']:>10.4f}\")\n",
    "    print(f\"{'Crisis Loss':<25} {train_metrics['crisis_loss']:>10.4f} {val_metrics['crisis_loss']:>10.4f}\")\n",
    "    print(f\"{'Informativeness Loss':<25} {train_metrics['info_loss']:>10.4f} {val_metrics['info_loss']:>10.4f}\")\n",
    "    print(f\"{'Emotion Accuracy':<25} {train_metrics['emotion_acc']:>10.4f} {val_metrics['emotion_acc']:>10.4f}\")\n",
    "    print(f\"{'Crisis Accuracy':<25} {train_metrics['crisis_acc']:>10.4f} {val_metrics['crisis_acc']:>10.4f}\")\n",
    "    print(f\"{'Info Accuracy':<25} {train_metrics['info_acc']:>10.4f} {val_metrics['info_acc']:>10.4f}\")\n",
    "    \n",
    "    # Save best model based on validation loss\n",
    "    if val_metrics['loss'] < best_val_loss:\n",
    "        best_val_loss = val_metrics['loss']\n",
    "        best_epoch = epoch + 1\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_loss': val_metrics['loss'],\n",
    "            'config': CONFIG,\n",
    "            'emotion_to_idx': EMOTION_TO_IDX,\n",
    "            'info_to_idx': INFO_TO_IDX,\n",
    "        }, os.path.join(CONFIG['SAVE_DIR'], 'best_model.pt'))\n",
    "        \n",
    "        print(f\"\\n  ** New best model saved (val_loss={best_val_loss:.4f}) **\")\n",
    "    else:\n",
    "        print(f\"\\n  Val loss did not improve (best={best_val_loss:.4f} at epoch {best_epoch})\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"\\u2705 Training complete in {elapsed/60:.1f} minutes\")\n",
    "print(f\"   Best val loss: {best_val_loss:.4f} (epoch {best_epoch})\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "epochs_range = range(1, CONFIG['EPOCHS'] + 1)\n",
    "\n",
    "# Total loss\n",
    "axes[0, 0].plot(epochs_range, history['train_loss'], 'b-o', label='Train')\n",
    "axes[0, 0].plot(epochs_range, history['val_loss'], 'r-o', label='Val')\n",
    "axes[0, 0].set_title('Total Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Emotion accuracy\n",
    "axes[0, 1].plot(epochs_range, history['train_emotion_acc'], 'b-o', label='Train')\n",
    "axes[0, 1].plot(epochs_range, history['val_emotion_acc'], 'r-o', label='Val')\n",
    "axes[0, 1].set_title('Emotion Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Crisis accuracy\n",
    "axes[1, 0].plot(epochs_range, history['train_crisis_acc'], 'b-o', label='Train')\n",
    "axes[1, 0].plot(epochs_range, history['val_crisis_acc'], 'r-o', label='Val')\n",
    "axes[1, 0].set_title('Crisis Accuracy')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Informativeness accuracy\n",
    "axes[1, 1].plot(epochs_range, history['train_info_acc'], 'b-o', label='Train')\n",
    "axes[1, 1].plot(epochs_range, history['val_info_acc'], 'r-o', label='Val')\n",
    "axes[1, 1].set_title('Informativeness Accuracy')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.suptitle('Multi-Task BERT Training Curves', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CONFIG['SAVE_DIR'], 'training_curves.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\u2705 Training curves saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Load Best Model & Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model checkpoint\n",
    "checkpoint = torch.load(\n",
    "    os.path.join(CONFIG['SAVE_DIR'], 'best_model.pt'),\n",
    "    map_location=device,\n",
    "    weights_only=False\n",
    ")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"\\u2705 Loaded best model from epoch {checkpoint['epoch']+1} (val_loss={checkpoint['val_loss']:.4f})\")\n",
    "\n",
    "# Final evaluation\n",
    "final_metrics = evaluate(\n",
    "    model, val_loader,\n",
    "    emotion_criterion, crisis_criterion, info_criterion,\n",
    "    device\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal Validation Metrics:\")\n",
    "print(f\"  Total Loss:       {final_metrics['loss']:.4f}\")\n",
    "print(f\"  Emotion Accuracy: {final_metrics['emotion_acc']:.4f}\")\n",
    "print(f\"  Crisis Accuracy:  {final_metrics['crisis_acc']:.4f}\")\n",
    "print(f\"  Info Accuracy:    {final_metrics['info_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"EMOTION CLASSIFICATION REPORT (13 classes)\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(\n",
    "    final_metrics['all_labels']['emotion'],\n",
    "    final_metrics['all_preds']['emotion'],\n",
    "    target_names=EMOTION_NAMES_13,\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CRISIS CLASSIFICATION REPORT (binary)\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(\n",
    "    final_metrics['all_labels']['crisis'],\n",
    "    final_metrics['all_preds']['crisis'],\n",
    "    target_names=['non_crisis', 'crisis'],\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"INFORMATIVENESS CLASSIFICATION REPORT (3 classes)\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(\n",
    "    final_metrics['all_labels']['info'],\n",
    "    final_metrics['all_preds']['info'],\n",
    "    target_names=INFO_NAMES,\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(22, 6))\n",
    "\n",
    "# Emotion confusion matrix\n",
    "cm_emotion = confusion_matrix(\n",
    "    final_metrics['all_labels']['emotion'],\n",
    "    final_metrics['all_preds']['emotion']\n",
    ")\n",
    "sns.heatmap(cm_emotion, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=EMOTION_NAMES_13, yticklabels=EMOTION_NAMES_13)\n",
    "axes[0].set_title('Emotion Confusion Matrix')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].tick_params(axis='y', rotation=0)\n",
    "\n",
    "# Crisis confusion matrix\n",
    "cm_crisis = confusion_matrix(\n",
    "    final_metrics['all_labels']['crisis'],\n",
    "    final_metrics['all_preds']['crisis']\n",
    ")\n",
    "sns.heatmap(cm_crisis, annot=True, fmt='d', cmap='Oranges', ax=axes[1],\n",
    "            xticklabels=['non_crisis', 'crisis'], yticklabels=['non_crisis', 'crisis'])\n",
    "axes[1].set_title('Crisis Confusion Matrix')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "\n",
    "# Informativeness confusion matrix\n",
    "cm_info = confusion_matrix(\n",
    "    final_metrics['all_labels']['info'],\n",
    "    final_metrics['all_preds']['info']\n",
    ")\n",
    "sns.heatmap(cm_info, annot=True, fmt='d', cmap='Greens', ax=axes[2],\n",
    "            xticklabels=['informative', 'not_inform.', 'not_related'],\n",
    "            yticklabels=['informative', 'not_inform.', 'not_related'])\n",
    "axes[2].set_title('Informativeness Confusion Matrix')\n",
    "axes[2].set_xlabel('Predicted')\n",
    "axes[2].set_ylabel('True')\n",
    "\n",
    "plt.suptitle('Multi-Task BERT - Confusion Matrices', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CONFIG['SAVE_DIR'], 'confusion_matrices.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\u2705 Confusion matrices saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Save Final Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenizer\n",
    "tokenizer.save_pretrained(CONFIG['SAVE_DIR'])\n",
    "\n",
    "# Save label mappings as JSON\n",
    "label_mappings = {\n",
    "    'emotion_to_idx': EMOTION_TO_IDX,\n",
    "    'idx_to_emotion': {str(k): v for k, v in IDX_TO_EMOTION.items()},\n",
    "    'info_to_idx': INFO_TO_IDX,\n",
    "    'idx_to_info': {str(k): v for k, v in IDX_TO_INFO.items()},\n",
    "    'emotion_merge_map': EMOTION_MERGE,\n",
    "    'emotion_names_13': EMOTION_NAMES_13,\n",
    "    'info_names': INFO_NAMES,\n",
    "}\n",
    "\n",
    "with open(os.path.join(CONFIG['SAVE_DIR'], 'label_mappings.json'), 'w') as f:\n",
    "    json.dump(label_mappings, f, indent=2)\n",
    "\n",
    "# Save training history\n",
    "with open(os.path.join(CONFIG['SAVE_DIR'], 'training_history.json'), 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"\\u2705 All artifacts saved to: {CONFIG['SAVE_DIR']}/\")\n",
    "print(f\"   - best_model.pt (model checkpoint)\")\n",
    "print(f\"   - vocab.txt, tokenizer_config.json (tokenizer)\")\n",
    "print(f\"   - label_mappings.json\")\n",
    "print(f\"   - training_history.json\")\n",
    "print(f\"   - training_curves.png\")\n",
    "print(f\"   - confusion_matrices.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Quick Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer, device):\n",
    "    \"\"\"Run inference on a single text. Returns predicted labels and confidences.\"\"\"\n",
    "    model.eval()\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=CONFIG['MAX_LENGTH'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask)\n",
    "    \n",
    "    emotion_probs = torch.softmax(logits['emotion'], dim=1)\n",
    "    crisis_probs = torch.softmax(logits['crisis'], dim=1)\n",
    "    info_probs = torch.softmax(logits['info'], dim=1)\n",
    "    \n",
    "    emotion_idx = emotion_probs.argmax(dim=1).item()\n",
    "    crisis_idx = crisis_probs.argmax(dim=1).item()\n",
    "    info_idx = info_probs.argmax(dim=1).item()\n",
    "    \n",
    "    return {\n",
    "        'emotion': IDX_TO_EMOTION[emotion_idx],\n",
    "        'emotion_confidence': emotion_probs[0, emotion_idx].item(),\n",
    "        'crisis': 'crisis' if crisis_idx == 1 else 'non_crisis',\n",
    "        'crisis_confidence': crisis_probs[0, crisis_idx].item(),\n",
    "        'informativeness': IDX_TO_INFO[info_idx],\n",
    "        'info_confidence': info_probs[0, info_idx].item(),\n",
    "    }\n",
    "\n",
    "\n",
    "# Test on sample texts\n",
    "test_texts = [\n",
    "    \"Massive earthquake hits the coast, buildings collapsed, people trapped under rubble\",\n",
    "    \"GOOOAL! France wins the World Cup! What an incredible match!\",\n",
    "    \"Please donate blood at the Red Cross center to help hurricane victims\",\n",
    "    \"Just finished watching the new Game of Thrones episode, it was okay\",\n",
    "    \"I am so scared, the wildfire is getting closer to our neighborhood\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"INFERENCE TEST\")\n",
    "print(\"=\" * 80)\n",
    "for text in test_texts:\n",
    "    result = predict(text, model, tokenizer, device)\n",
    "    display_text = f'\"{text[:80]}...\"' if len(text) > 80 else f'\"{text}\"'\n",
    "    print(f\"\\nText: {display_text}\")\n",
    "    print(f\"  Emotion: {result['emotion']} ({result['emotion_confidence']:.3f})\")\n",
    "    print(f\"  Crisis:  {result['crisis']} ({result['crisis_confidence']:.3f})\")\n",
    "    print(f\"  Info:    {result['informativeness']} ({result['info_confidence']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"MULTI-TASK BERT TRAINING COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nDataset: {CONFIG['DATA_PATH']}\")\n",
    "print(f\"  Train: {len(train_df):,} | Val: {len(val_df):,}\")\n",
    "\n",
    "print(f\"\\nBest Model (epoch {best_epoch}):\")\n",
    "print(f\"  Val Loss:       {best_val_loss:.4f}\")\n",
    "print(f\"  Emotion Acc:    {final_metrics['emotion_acc']:.4f}\")\n",
    "print(f\"  Crisis Acc:     {final_metrics['crisis_acc']:.4f}\")\n",
    "print(f\"  Info Acc:       {final_metrics['info_acc']:.4f}\")\n",
    "\n",
    "print(f\"\\nArtifacts saved to: {CONFIG['SAVE_DIR']}/\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  1. If using 10K sample: re-run with full 52.8K dataset (change DATA_PATH in CONFIG)\")\n",
    "print(f\"  2. Apply trained model to original full datasets (67K crisis + 2.3M non-crisis)\")\n",
    "print(f\"  3. Extract emotion features per tweet for RL agent\")\n",
    "print(f\"  4. Create episodes and hourly aggregations for RL training\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
